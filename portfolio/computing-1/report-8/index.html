<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Portfolio Report 8: Matrices | Jake Spiteri</title><meta name=keywords content><meta name=description content="Matrices In this report we will look at how R treats matrices.
We will explore the Matrix package, which extends the basic R functionality for matrices. For example, it seems odd that base R does not have a method of determining the rank of a matrix up to a certain tolerance — the Matrix package adds this functionality.
Dense matrices A matrix is a two dimensional data structure in R."><meta name=author content="Jake Spiteri"><link rel=canonical href=https://jakespiteri.co.uk/portfolio/computing-1/report-8/><meta name=google-site-verification content="XYZabc"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css integrity=sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js integrity=sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link crossorigin=anonymous href=/assets/css/stylesheet.ccdd7c01ba69b30dd10ab397e0d0f0774c08df41d39f6b53e16f862223c92b98.css integrity="sha256-zN18Abppsw3RCrOX4NDwd0wI30HTn2tT4W+GIiPJK5g=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://jakespiteri.co.uk/favi.png><link rel=icon type=image/png sizes=16x16 href=https://jakespiteri.co.uk/favi.png><link rel=icon type=image/png sizes=32x32 href=https://jakespiteri.co.uk/favi.png><link rel=apple-touch-icon href=https://jakespiteri.co.uk/favi.png><link rel=mask-icon href=https://jakespiteri.co.uk/favi.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Portfolio Report 8: Matrices"><meta property="og:description" content="Matrices In this report we will look at how R treats matrices.
We will explore the Matrix package, which extends the basic R functionality for matrices. For example, it seems odd that base R does not have a method of determining the rank of a matrix up to a certain tolerance — the Matrix package adds this functionality.
Dense matrices A matrix is a two dimensional data structure in R."><meta property="og:type" content="article"><meta property="og:url" content="https://jakespiteri.co.uk/portfolio/computing-1/report-8/"><meta property="og:image" content="https://jakespiteri.co.uk/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="portfolio"><meta property="og:site_name" content="Jake Spiteri"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jakespiteri.co.uk/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Portfolio Report 8: Matrices"><meta name=twitter:description content="Matrices In this report we will look at how R treats matrices.
We will explore the Matrix package, which extends the basic R functionality for matrices. For example, it seems odd that base R does not have a method of determining the rank of a matrix up to a certain tolerance — the Matrix package adds this functionality.
Dense matrices A matrix is a two dimensional data structure in R."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Portfolio","item":"https://jakespiteri.co.uk/portfolio/"},{"@type":"ListItem","position":2,"name":"Statistical Computing 1","item":"https://jakespiteri.co.uk/portfolio/computing-1/"},{"@type":"ListItem","position":3,"name":"Portfolio Report 8: Matrices","item":"https://jakespiteri.co.uk/portfolio/computing-1/report-8/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Portfolio Report 8: Matrices","name":"Portfolio Report 8: Matrices","description":"Matrices In this report we will look at how R treats matrices.\nWe will explore the Matrix package, which extends the basic R functionality for matrices. For example, it seems odd that base R does not have a method of determining the rank of a matrix up to a certain tolerance — the Matrix package adds this functionality.\nDense matrices A matrix is a two dimensional data structure in R.","keywords":[],"articleBody":" Matrices In this report we will look at how R treats matrices.\nWe will explore the Matrix package, which extends the basic R functionality for matrices. For example, it seems odd that base R does not have a method of determining the rank of a matrix up to a certain tolerance — the Matrix package adds this functionality.\nDense matrices A matrix is a two dimensional data structure in R. We specify a matrix by its columns, and we can change this default functionality by setting byrow=T. We can assign names to the rows and columns of a matrix, and easily change these names by redefining colnames() and rownames(). This is shown below.\n# matrices are defined by columns m \u003c- matrix(1:4, 2, 2) m ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 # print the class of the matrix object class(m) ## [1] \"matrix\" \"array\" # we can observe attributes attributes(m) ## $dim ## [1] 2 2 # we can print this attribute dim(m) ## [1] 2 2 # we can assign row and column names when creating the matrix m \u003c- matrix(c(rnorm(2,0,1), rnorm(2, 1, 1)), 2, 2, dimnames = list(c(\"obs 1\", \"obs 2\"), c(\"r.v. 1\", \"r.v. 2\"))) m ## r.v. 1 r.v. 2 ## obs 1 0.001076783 1.7477260 ## obs 2 1.525191976 0.2751858 # print colnames colnames(m) ## [1] \"r.v. 1\" \"r.v. 2\" # print rownames rownames(m) ## [1] \"obs 1\" \"obs 2\" # redefine colnames colnames(m) \u003c- c(\"new col name 1\", \"new col name 2\") # redefine rownames rownames(m) \u003c- c(\"new row name 1\", \"new row name 2\") # print new matrix m ## new col name 1 new col name 2 ## new row name 1 0.001076783 1.7477260 ## new row name 2 1.525191976 0.2751858 It’s quite odd but when we select a row or column of a matrix, R returns a vector and loses the matrix dimensions. When selecting a row of a \\(2 \\times 2\\) matrix we would expect a vector of dimension \\(1 \\times 2\\).\n# select row m[1,] ## new col name 1 new col name 2 ## 0.001076783 1.747725988 # check dimensions of row dim(m[1,]) ## NULL In order to change this behavior, we can specify drop=F.\n# select row m[1,,drop=F] ## new col name 1 new col name 2 ## new row name 1 0.001076783 1.747726 # check dimensions dim(m[1,,drop=F]) ## [1] 1 2 This is inconvenient but it allows us to maintain the dimensions of a matrix when indexing. When selecting a column of a matrix we would expect to obtain a column vector, but this is also not the case unless we specify drop=F.\nR also has higher-dimensional data structures called arrays. We can think of an array as stacked matrices. For example, specifying dimension (4,5,6) creates 6 matrices with 4 rows and 5 columns.\nBelow we will specify an array of dimension (2,2,3). Recall that R specifies a matrix by its columns — we will demonstrate this.\narr \u003c- array(1:3, c(2,2,3)) dim(arr) ## [1] 2 2 3 arr[,,1] ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 1 arr[,,2] ## [,1] [,2] ## [1,] 2 1 ## [2,] 3 2 arr[,,3] ## [,1] [,2] ## [1,] 3 2 ## [2,] 1 3 # We can also select the rows or columns arr[1,,] ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 3 1 2 Note in the above that when we do arr[1,,] this selects the first row of each matrix, which are \\((1,3)\\), \\((2,1)\\), and \\((3,2)\\), and puts them into a matrix.\nSolving linear systems A common problem encountered in linear algebra is solving a system of linear equations. That is, finding \\(x\\) that solves \\(Ax = b\\). On paper we would simply write \\(x = A^{-1}b\\). There are two ways of implementing this solution in R: we could use x \u003c- solve(A) %*% b; we could directly solve the system using x = solve(A, b). Naturally we would expect these solutions to be equal, but this is not necessarily the case in R. We shall show this by an example with Hilbert matrices which are well known to be close to singular.\nA \u003c- as.matrix(Hilbert(9)) # finding the rank is inconsistent rankMatrix(A) ## [1] 9 ## attr(,\"method\") ## [1] \"tolNorm2\" ## attr(,\"useGrad\") ## [1] FALSE ## attr(,\"tol\") ## [1] 1.998401e-15 rankMatrix(A, tol = 1e-9) ## [1] 7 ## attr(,\"method\") ## [1] \"tolNorm2\" ## attr(,\"useGrad\") ## [1] FALSE ## attr(,\"tol\") ## [1] 1e-09 # show nearly singular det(A) ## [1] 9.720265e-43 # create a linear system x \u003c- matrix(rnorm(9), 9, 1) b \u003c- A %*% x # solve x1 \u003c- solve(A) %*% b x2 \u003c- solve(A, b) # compute some metric of the error norm(x-x1) ## [1] 3.990248e-05 norm(x-x2) ## [1] 2.858611e-05 # compare the residuals norm(b - A %*% x1) ## [1] 6.485157e-08 norm(b - A %*% x2) ## [1] 2.775558e-16 We see that solving the system of equations directly is far superior, both in terms of accuracy and speed. In R we should always avoid directly computing the inverse of a matrix, unless the inverted matrix will be used multiple times to solve linear systems. Even then, there are better ways to approach the problem. We can always look at different decompositions of the matrix and find a more numerically stable method of solving the linear system. This is what functions such as lm() do — they do not directly solve for predicted coefficients using \\(\\hat{\\beta} = (X^TX)^{-1}X^TY\\), they rely on the QR decomposition. Before we compute the inverse of a matrix we should try to find a more elegant solution by decomposing the matrices involved.\nNumerical stability and finite precision arithmetic In most programming packages, a floating point number is stored as a ‘double’ precision number. According to the IEEE754 standard a double number consists of 64 binary bits arranged as follows:\nsign bit: 1 bit exponent bit: 11 bits significant precision: 52 bits Thus, we are limited in the length of the numbers we can store. This means there exist smallest and largest numbers in R. We can see this demonstrated below.\nc(2^(-1075), 2^(-1074), 2^1023, 2^1024, 2^1024 / 2^1024) ## [1] 0.000000e+00 4.940656e-324 8.988466e+307 Inf NaN We see that \\(2^{1023}\\) is the largest number that can be stored. Any higher and R returns Inf. Note that we can no longer do arithmetic with Inf — even a simple operation such as \\(2^{1024}/2^{1024}\\) cannot be computed.\nWe have 52 precision bits, so we can expect an error rate of approximately \\(10^{-16}\\) (\\(2^{-52} \\approx 2.22 \\times 10^{-16}\\)) in numerical computations of double numbers. This is shown below. The R documentation mentions that we should avoid using more than 15 digits.\n# R will not suggest digits \u003e= 16 # so if we add a very small number to 1, it will not print print(1 + 1e-14) ## [1] 1 # specify digits print(1 + 1e-14, digits=15) ## [1] 1.00000000000001 These numerical characteristics of the machine are also stored in R. We can access them using .Machine. For example, we can find the smallest \\(x\\) such that \\(1 + x \\neq 1\\) (the machine epsilon) using .Machine$double.eps. .Machine stores many interesting characteristics and is definitely worth exploring.\n# .Machine$double.eps ## [1] 2.220446e-16 Arithmetic with double floating point numbers is not so easy in R. This is because of numerical errors — this is a problem for even trivial calculations as shown below. These errors occur because floating points can only represent the dyadic rationals, which are numbers with denominators which are powers of 2. Hence 0.1 is simply approximated as a dyadic rational. This leads to unexpected results, for example, 0.1+0.2 == 0.3 is FALSE!\n# not zero 0.1+0.2-0.3 ## [1] 5.551115e-17 # looks okay 0.1 + 0.2 ## [1] 0.3 # check 0.1 + 0.2 == 0.3 ## [1] FALSE # all.equal uses a tolerance parameter all.equal(0.1 + 0.2, 0.3) ## [1] TRUE We see that the equality comparison == often does not behave the way we expect it to. When working with double floating point numbers we should avoid testing equality using == and instead use all.equal() which ignores machine errors using a tolerance parameter.\nR also has an integer data type ‘long’.\n# 1L seems to be the same as 1 1L ## [1] 1 # test equality 1 == 1L ## [1] TRUE identical(1, 1L) ## [1] FALSE Given that error is introduced with arithmetic operations, the errors produced by matrix multiplication are much larger due to the numerous operations of addition and scalar multiplication.\nSuppose we have matrices \\(A \\in \\mathbb{R}^{n \\times n}\\), \\(B \\in \\mathbb{R}^{n \\times m}\\), and \\(C \\in \\mathbb{R}^{m \\times 1}\\). Then the flop cost of computing \\(AB\\) is of the order \\(\\mathcal{O}(n^2m)\\) as it requires \\(n^2m\\) multiplications. The flop cost of computing \\(BC\\) is of the order \\(\\mathcal{O}(nm)\\). Let \\(m=n\\), then to compute \\(ABC\\) has cost of the order \\(\\mathcal{O}(n^3)\\) and to compute \\(A(BC)\\) has cost of the order \\(\\mathcal{O}(n^2)\\). Thus, whilst these quantities are the same algebraically, the order of multiplications impacts the number of multiplications and thus impacts the error produced. In the following example we expect computing \\(ABC\\) to have an error approximately \\(10\\) times larger than computing \\(A(BC)\\).\n# check error for matrix addition and subtraction A \u003c- matrix(rnorm(100),10,10); B \u003c- matrix(rnorm(100),10,10); C \u003c- rnorm(10) summary(c((A + B) - A - B)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -2.220e-16 0.000e+00 0.000e+00 2.559e-18 0.000e+00 2.220e-16 # check error for matrix multiplication summary(c(A%*%B%*%C - A%*%(B%*%C))) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -3.553e-15 -1.554e-15 2.220e-16 -2.776e-16 1.221e-15 1.776e-15 # check computation times n \u003c- 5000 A \u003c- matrix(rnorm(n^2), n, n); B \u003c- matrix(rnorm(n^2), n, n); C \u003c- rnorm(n) c(system.time(A%*%B%*%C), system.time(A%*%(B%*%C))) ## user.self sys.self elapsed user.child sys.child user.self sys.self ## 107.929 0.083 108.051 0.000 0.000 0.083 0.000 ## elapsed user.child sys.child ## 0.083 0.000 0.000 When working with matrices we must think carefully about what we are trying to do, in order to avoid unnecessary multiplications which can introduce numerical errors.\nSuppose we want to sum the diagonal entries of the matrix product \\(AB\\), for \\(A \\in \\mathbb{R}^{n \\times m}\\), \\(B \\in \\mathbb{R}^{m \\times n}\\) where \\(m \u003c\u003c n\\). Note the costs of forming \\(AB\\) compared to \\(BA\\) (\\(\\mathcal{O}(n^2m)\\) compared to \\(\\mathcal{O}(m^2n)\\)). In R there are multiple ways we can do this.\nWe can compute the matrix product \\(AB\\), extract the diagonal entries, and sum them.\nWe can instead compute the matrix product \\(BA\\), extract the diagonal entries, and sum them. This uses the fact that \\(\\text{tr}(AB) = \\text{tr}(BA)\\).\nWe can sum the elements of \\(A * B^T\\) (element-wise multiplication), since \\(\\text{tr} = \\sum_{i,j} A_{ij} B_{ji}\\).\nn \u003c- 10000; m \u003c- 1000 A \u003c- matrix(rnorm(n*m), n, m); B \u003c- matrix(rnorm(n*m), m, n) # first, second, and third method first \u003c- sum(diag(A %*% B)) second \u003c- sum(diag(B %*% A)) third \u003c- sum(A * t(B)) # compare errors summary(first - second) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -2.046e-12 -2.046e-12 -2.046e-12 -2.046e-12 -2.046e-12 -2.046e-12 summary(first - third) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -2.274e-12 -2.274e-12 -2.274e-12 -2.274e-12 -2.274e-12 -2.274e-12 summary(second - third) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -2.274e-13 -2.274e-13 -2.274e-13 -2.274e-13 -2.274e-13 -2.274e-13 # compare computation time system.time(sum(diag(A %*% B))) # first ## user system elapsed ## 86.641 0.248 86.934 system.time(sum(diag(B %*% A))) # second ## user system elapsed ## 8.620 0.020 8.647 system.time(sum(A * t(B))) # third ## user system elapsed ## 0.114 0.024 0.137 The second method is much better than the first both in terms of precision and run time. The third method is better than the second method.\nSparse Matrices The R packages Matrix provides additional functionality for both dense matrices and sparse matrices. In the Matrix packages, dense matrices are stored as dgeMatrix objects, and sparse matrices are stored as dgCMatrix objects. A useful function we have already seen is rankMatrix which provides the rank of the input matrix up to a certain tolerance.\nlibrary(Matrix) A \u003c- Matrix(c(1,1,2,2),2,2) B \u003c- Matrix(c(1,1,2,2) + rnorm(4)/1e10,2,2) c(rankMatrix(A), rankMatrix(B), rankMatrix(B, tol=1e-7)) ## [1] 1 2 1 A sparse matrix is one in which most entries are equal to zero. It’s inefficient to store all of these zeros in memory, and so we only store the non-zero entries.\nset.seed(25) nrows \u003c- ncols \u003c- 500 entries \u003c- sample(c(0,1,2),nrows*ncols,TRUE,c(0.98, 0.01, 0.01)) m1 \u003c- matrix(entries, nrows, ncols) m2 \u003c- Matrix(entries, nrows, ncols, sparse = TRUE) c(class(m1), class(m2)) ## [1] \"matrix\" \"array\" \"dgCMatrix\" m1[1:2,1:10] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 0 0 0 0 0 0 0 0 0 0 ## [2,] 0 1 0 0 0 0 0 0 0 1 m2[1:2,1:10] ## 2 x 10 sparse Matrix of class \"dgCMatrix\" ## ## [1,] . . . . . . . . . . ## [2,] . 1 . . . . . . . 1 c(object.size(m1), object.size(m2)) ## [1] 2000216 62904 We see that a sparse matrix defined using the Matrix package has class dgCMatrix. The ‘d’ stands for digit, the ‘g’ stands for general, and the ‘C’ stands for column. We can convert a dgCMatrix to a dgeMatrix — the standard class for dense matrices — but we will lose the memory improvements of the compressed sparse format. Alternatives to the dgCMatrix are the dgRMatrix and dgTMatrix classes. We can convert a dgCMatrix into a dgTMatrix (a triplet matrix), but not a dgRMatrix.\n# display the structure str(m2, max.level = 1) ## Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots str(m2) ## Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots ## ..@ i : int [1:4950] 5 46 141 211 315 327 380 430 482 485 ... ## ..@ p : int [1:501] 0 10 21 29 42 47 54 58 67 76 ... ## ..@ Dim : int [1:2] 500 500 ## ..@ Dimnames:List of 2 ## .. ..$ : NULL ## .. ..$ : NULL ## ..@ x : num [1:4950] 2 1 1 1 1 1 1 1 1 1 ... ## ..@ factors : list() which(m2[,1]\u003e0) ## [1] 6 47 142 212 316 328 381 431 483 486 # show difference in memory size object.size(as(m2, 'dgeMatrix')) ## as(, \"dgeMatrix\") is deprecated since Matrix 1.5-0; do as(., \"unpackedMatrix\") instead ## 2001176 bytes object.size(as(m2, 'dgTMatrix')) ## 80696 bytes object.size(m2) # dgCMatrix ## 62904 bytes # print the matrices before and after coercion m2[1:2, 1:10] ## 2 x 10 sparse Matrix of class \"dgCMatrix\" ## ## [1,] . . . . . . . . . . ## [2,] . 1 . . . . . . . 1 as(m2, 'dgTMatrix')[1:2, 1:10] ## 2 x 10 sparse Matrix of class \"dgTMatrix\" ## ## [1,] . . . . . . . . . . ## [2,] . 1 . . . . . . . 1 Operations for sparse matrices A \u003c- B \u003c- Matrix(c(1,1,0,0,0,1),3,2, sparse=TRUE) A ## 3 x 2 sparse Matrix of class \"dgCMatrix\" ## ## [1,] 1 . ## [2,] 1 . ## [3,] . 1 # division maintains class A/10 ## 3 x 2 sparse Matrix of class \"dgCMatrix\" ## ## [1,] 0.1 . ## [2,] 0.1 . ## [3,] . 0.1 # addition and subtraction change class to dgeMatrix A+1; A-1 ## 3 x 2 Matrix of class \"dgeMatrix\" ## [,1] [,2] ## [1,] 2 1 ## [2,] 2 1 ## [3,] 1 2 ## 3 x 2 Matrix of class \"dgeMatrix\" ## [,1] [,2] ## [1,] 0 -1 ## [2,] 0 -1 ## [3,] -1 0 # matrix multiplication changes class A %*% c(1,1) ## 3 x 1 Matrix of class \"dgeMatrix\" ## [,1] ## [1,] 1 ## [2,] 1 ## [3,] 1 # addition and subtraction of two dgCMatrix objects produces an object of the same class A+B; A-B ## 3 x 2 sparse Matrix of class \"dgCMatrix\" ## ## [1,] 2 . ## [2,] 2 . ## [3,] . 2 ## 3 x 2 sparse Matrix of class \"dgCMatrix\" ## ## [1,] 0 . ## [2,] 0 . ## [3,] . 0 # matrix multiplication of two dgCMatrix objects gives a dgCMatrix object A %*% t(B) ## 3 x 3 sparse Matrix of class \"dgCMatrix\" ## ## [1,] 1 1 . ## [2,] 1 1 . ## [3,] . . 1 # row or column binding dgCMatrix objects returns a dgCMatrix cbind(A,A); rbind(A,A) ## 3 x 4 sparse Matrix of class \"dgCMatrix\" ## ## [1,] 1 . 1 . ## [2,] 1 . 1 . ## [3,] . 1 . 1 ## 6 x 2 sparse Matrix of class \"dgCMatrix\" ## ## [1,] 1 . ## [2,] 1 . ## [3,] . 1 ## [4,] 1 . ## [5,] 1 . ## [6,] . 1 Solving large linear systems Solving linear systems for very large and sparse systems is very difficult, as the inverse of a sparse matrix is not necessarily sparse. To avoid these problems we should directly solve the linear system using solve(A, b).\nnrow \u003c- ncol \u003c- 500 A \u003c- Matrix(sample(c(0,1), nrow*ncol, TRUE, c(0.98, 0.02)), nrow, ncol, sparse=TRUE) A.inv \u003c- solve(A) # object sizes c(object.size(A), object.size(A.inv)) ## [1] 1884440 2001176 # possible elements nrow*ncol ## [1] 250000 # entries in A nnzero(A) ## [1] 4897 # entries in A.inv nnzero(A.inv) ## [1] 250000 ","wordCount":"2879","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Jake Spiteri"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://jakespiteri.co.uk/portfolio/computing-1/report-8/"},"publisher":{"@type":"Organization","name":"Jake Spiteri","logo":{"@type":"ImageObject","url":"https://jakespiteri.co.uk/favi.png"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://jakespiteri.co.uk/ accesskey=h title="Home (Alt + H)"><div class=custom-logo><span class=logo__mark></span>
<span class=logo__text>>$ cd /home</span>
<span class=logo__cursor style=background-color:#1290ff></span></div></a><div class=logo-switches></div></div><ul id=menu style=font-family:monospace,monospace><li><a href=https://jakespiteri.co.uk/about/ title=/about><span>/about</span></a></li><li><a href=https://jakespiteri.co.uk/portfolio/ title=/portfolio><span>/portfolio</span></a></li><li><a href=https://jakespiteri.co.uk/blog/ title=/blog><span>/blog</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://jakespiteri.co.uk/>Home</a>&nbsp;»&nbsp;<a href=https://jakespiteri.co.uk/portfolio/>Portfolio</a>&nbsp;»&nbsp;<a href=https://jakespiteri.co.uk/portfolio/computing-1/>Statistical Computing 1</a></div><h1 class=post-title>Portfolio Report 8: Matrices</h1><div class=post-meta>Jake Spiteri&nbsp;|&nbsp;<a href=https://github.com/jakespiteri.github.io/content/portfolio/computing-1/Report-8/index.html rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><div id=matrices class="section level1"><h1>Matrices</h1><p>In this report we will look at how <code>R</code> treats matrices.</p><p>We will explore the <code>Matrix</code> package, which extends the basic <code>R</code> functionality for matrices. For example, it seems odd that base <code>R</code> does not have a method of determining the rank of a matrix up to a certain tolerance — the <code>Matrix</code> package adds this functionality.</p><div id=dense-matrices class="section level2"><h2>Dense matrices</h2><p>A matrix is a two dimensional data structure in <code>R</code>. We specify a matrix by its columns, and we can change this default functionality by setting <code>byrow=T</code>. We can assign names to the rows and columns of a matrix, and easily change these names by redefining <code>colnames(&lt;matrix>)</code> and <code>rownames(&lt;matrix>)</code>. This is shown below.</p><pre class=r><code># matrices are defined by columns
m &lt;- matrix(1:4, 2, 2)
m</code></pre><pre><code>##      [,1] [,2]
## [1,]    1    3
## [2,]    2    4</code></pre><pre class=r><code># print the class of the matrix object
class(m)</code></pre><pre><code>## [1] &quot;matrix&quot; &quot;array&quot;</code></pre><pre class=r><code># we can observe attributes
attributes(m)</code></pre><pre><code>## $dim
## [1] 2 2</code></pre><pre class=r><code># we can print this attribute
dim(m)</code></pre><pre><code>## [1] 2 2</code></pre><pre class=r><code># we can assign row and column names when creating the matrix
m &lt;- matrix(c(rnorm(2,0,1), rnorm(2, 1, 1)), 2, 2, 
            dimnames = list(c(&quot;obs 1&quot;, &quot;obs 2&quot;), c(&quot;r.v. 1&quot;, &quot;r.v. 2&quot;)))
m</code></pre><pre><code>##            r.v. 1    r.v. 2
## obs 1 0.001076783 1.7477260
## obs 2 1.525191976 0.2751858</code></pre><pre class=r><code># print colnames
colnames(m)</code></pre><pre><code>## [1] &quot;r.v. 1&quot; &quot;r.v. 2&quot;</code></pre><pre class=r><code># print rownames
rownames(m)</code></pre><pre><code>## [1] &quot;obs 1&quot; &quot;obs 2&quot;</code></pre><pre class=r><code># redefine colnames
colnames(m) &lt;- c(&quot;new col name 1&quot;, &quot;new col name 2&quot;)

# redefine rownames
rownames(m) &lt;- c(&quot;new row name 1&quot;, &quot;new row name 2&quot;)

# print new matrix
m</code></pre><pre><code>##                new col name 1 new col name 2
## new row name 1    0.001076783      1.7477260
## new row name 2    1.525191976      0.2751858</code></pre><p>It’s quite odd but when we select a row or column of a matrix, <code>R</code> returns a vector and loses the matrix dimensions. When selecting a row of a <span class="math inline">\(2 \times 2\)</span> matrix we would expect a vector of dimension <span class="math inline">\(1 \times 2\)</span>.</p><pre class=r><code># select row
m[1,]</code></pre><pre><code>## new col name 1 new col name 2 
##    0.001076783    1.747725988</code></pre><pre class=r><code># check dimensions of row
dim(m[1,])</code></pre><pre><code>## NULL</code></pre><p>In order to change this behavior, we can specify <code>drop=F</code>.</p><pre class=r><code># select row
m[1,,drop=F]</code></pre><pre><code>##                new col name 1 new col name 2
## new row name 1    0.001076783       1.747726</code></pre><pre class=r><code># check dimensions
dim(m[1,,drop=F])</code></pre><pre><code>## [1] 1 2</code></pre><p>This is inconvenient but it allows us to maintain the dimensions of a matrix when indexing. When selecting a column of a matrix we would expect to obtain a column vector, but this is also not the case unless we specify <code>drop=F</code>.</p><p><code>R</code> also has higher-dimensional data structures called arrays. We can think of an array as stacked matrices. For example, specifying dimension <code>(4,5,6)</code> creates 6 matrices with 4 rows and 5 columns.</p><p>Below we will specify an array of dimension <code>(2,2,3)</code>. Recall that <code>R</code> specifies a matrix by its columns — we will demonstrate this.</p><pre class=r><code>arr &lt;- array(1:3, c(2,2,3))

dim(arr)</code></pre><pre><code>## [1] 2 2 3</code></pre><pre class=r><code>arr[,,1]</code></pre><pre><code>##      [,1] [,2]
## [1,]    1    3
## [2,]    2    1</code></pre><pre class=r><code>arr[,,2]</code></pre><pre><code>##      [,1] [,2]
## [1,]    2    1
## [2,]    3    2</code></pre><pre class=r><code>arr[,,3]</code></pre><pre><code>##      [,1] [,2]
## [1,]    3    2
## [2,]    1    3</code></pre><pre class=r><code># We can also select the rows or columns
arr[1,,]</code></pre><pre><code>##      [,1] [,2] [,3]
## [1,]    1    2    3
## [2,]    3    1    2</code></pre><p>Note in the above that when we do <code>arr[1,,]</code> this selects the first row of each matrix, which are <span class="math inline">\((1,3)\)</span>, <span class="math inline">\((2,1)\)</span>, and <span class="math inline">\((3,2)\)</span>, and puts them into a matrix.</p></div><div id=solving-linear-systems class="section level2"><h2>Solving linear systems</h2><p>A common problem encountered in linear algebra is solving a system of linear equations. That is, finding <span class="math inline">\(x\)</span> that solves <span class="math inline">\(Ax = b\)</span>. On paper we would simply write <span class="math inline">\(x = A^{-1}b\)</span>. There are two ways of implementing this solution in <code>R</code>: we could use <code>x &lt;- solve(A) %*% b</code>; we could directly solve the system using <code>x = solve(A, b)</code>. Naturally we would expect these solutions to be equal, but this is not necessarily the case in <code>R</code>. We shall show this by an example with Hilbert matrices which are well known to be close to singular.</p><pre class=r><code>A &lt;- as.matrix(Hilbert(9))

# finding the rank is inconsistent
rankMatrix(A)</code></pre><pre><code>## [1] 9
## attr(,&quot;method&quot;)
## [1] &quot;tolNorm2&quot;
## attr(,&quot;useGrad&quot;)
## [1] FALSE
## attr(,&quot;tol&quot;)
## [1] 1.998401e-15</code></pre><pre class=r><code>rankMatrix(A, tol = 1e-9)</code></pre><pre><code>## [1] 7
## attr(,&quot;method&quot;)
## [1] &quot;tolNorm2&quot;
## attr(,&quot;useGrad&quot;)
## [1] FALSE
## attr(,&quot;tol&quot;)
## [1] 1e-09</code></pre><pre class=r><code># show nearly singular
det(A)</code></pre><pre><code>## [1] 9.720265e-43</code></pre><pre class=r><code># create a linear system
x &lt;- matrix(rnorm(9), 9, 1)
b &lt;- A %*% x

# solve
x1 &lt;- solve(A) %*% b
x2 &lt;- solve(A, b)

# compute some metric of the error
norm(x-x1)</code></pre><pre><code>## [1] 3.990248e-05</code></pre><pre class=r><code>norm(x-x2)</code></pre><pre><code>## [1] 2.858611e-05</code></pre><pre class=r><code># compare the residuals
norm(b - A %*% x1)</code></pre><pre><code>## [1] 6.485157e-08</code></pre><pre class=r><code>norm(b - A %*% x2)</code></pre><pre><code>## [1] 2.775558e-16</code></pre><p>We see that solving the system of equations directly is far superior, both in terms of accuracy and speed. In <code>R</code> we should always avoid directly computing the inverse of a matrix, unless the inverted matrix will be used multiple times to solve linear systems. Even then, there are better ways to approach the problem. We can always look at different decompositions of the matrix and find a more numerically stable method of solving the linear system. This is what functions such as <code>lm()</code> do — they do not directly solve for predicted coefficients using <span class="math inline">\(\hat{\beta} = (X^TX)^{-1}X^TY\)</span>, they rely on the QR decomposition. Before we compute the inverse of a matrix we should try to find a more elegant solution by decomposing the matrices involved.</p></div><div id=numerical-stability-and-finite-precision-arithmetic class="section level2"><h2>Numerical stability and finite precision arithmetic</h2><p>In most programming packages, a floating point number is stored as a ‘double’ precision number. According to the IEEE754 standard a double number consists of 64 binary bits arranged as follows:</p><ul><li>sign bit: 1 bit</li><li>exponent bit: 11 bits</li><li>significant precision: 52 bits</li></ul><p>Thus, we are limited in the length of the numbers we can store. This means there exist smallest and largest numbers in <code>R</code>. We can see this demonstrated below.</p><pre class=r><code>c(2^(-1075), 2^(-1074), 2^1023, 2^1024, 2^1024 / 2^1024)</code></pre><pre><code>## [1]  0.000000e+00 4.940656e-324 8.988466e+307           Inf           NaN</code></pre><p>We see that <span class="math inline">\(2^{1023}\)</span> is the largest number that can be stored. Any higher and <code>R</code> returns <code>Inf</code>. Note that we can no longer do arithmetic with <code>Inf</code> — even a simple operation such as <span class="math inline">\(2^{1024}/2^{1024}\)</span> cannot be computed.</p><p>We have 52 precision bits, so we can expect an error rate of approximately <span class="math inline">\(10^{-16}\)</span> (<span class="math inline">\(2^{-52} \approx 2.22 \times 10^{-16}\)</span>) in numerical computations of double numbers. This is shown below. The <code>R</code> documentation mentions that we should avoid using more than 15 digits.</p><pre class=r><code># R will not suggest digits &gt;= 16
# so if we add a very small number to 1, it will not print
print(1 + 1e-14)</code></pre><pre><code>## [1] 1</code></pre><pre class=r><code># specify digits
print(1 + 1e-14, digits=15)</code></pre><pre><code>## [1] 1.00000000000001</code></pre><p>These numerical characteristics of the machine are also stored in <code>R</code>. We can access them using <code>.Machine</code>. For example, we can find the smallest <span class="math inline">\(x\)</span> such that <span class="math inline">\(1 + x \neq 1\)</span> (the machine epsilon) using <code>.Machine$double.eps</code>. <code>.Machine</code> stores many interesting characteristics and is definitely worth exploring.</p><pre class=r><code># 
.Machine$double.eps</code></pre><pre><code>## [1] 2.220446e-16</code></pre><p>Arithmetic with double floating point numbers is not so easy in <code>R</code>. This is because of numerical errors — this is a problem for even trivial calculations as shown below. These errors occur because floating points can only represent the dyadic rationals, which are numbers with denominators which are powers of 2. Hence 0.1 is simply approximated as a dyadic rational. This leads to unexpected results, for example, <code>0.1+0.2 == 0.3</code> is <code>FALSE</code>!</p><pre class=r><code># not zero
0.1+0.2-0.3</code></pre><pre><code>## [1] 5.551115e-17</code></pre><pre class=r><code># looks okay
0.1 + 0.2</code></pre><pre><code>## [1] 0.3</code></pre><pre class=r><code># check
0.1 + 0.2 == 0.3</code></pre><pre><code>## [1] FALSE</code></pre><pre class=r><code># all.equal uses a tolerance parameter
all.equal(0.1 + 0.2, 0.3)</code></pre><pre><code>## [1] TRUE</code></pre><p>We see that the equality comparison <code>==</code> often does not behave the way we expect it to. When working with double floating point numbers we should avoid testing equality using <code>==</code> and instead use <code>all.equal()</code> which ignores machine errors using a tolerance parameter.</p><p><code>R</code> also has an integer data type ‘long’.</p><pre class=r><code># 1L seems to be the same as 1
1L</code></pre><pre><code>## [1] 1</code></pre><pre class=r><code># test equality
1 == 1L</code></pre><pre><code>## [1] TRUE</code></pre><pre class=r><code>identical(1, 1L)</code></pre><pre><code>## [1] FALSE</code></pre><p>Given that error is introduced with arithmetic operations, the errors produced by matrix multiplication are much larger due to the numerous operations of addition and scalar multiplication.</p><p>Suppose we have matrices <span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span>, <span class="math inline">\(B \in \mathbb{R}^{n \times m}\)</span>, and <span class="math inline">\(C \in \mathbb{R}^{m \times 1}\)</span>. Then the flop cost of computing <span class="math inline">\(AB\)</span> is of the order <span class="math inline">\(\mathcal{O}(n^2m)\)</span> as it requires <span class="math inline">\(n^2m\)</span> multiplications. The flop cost of computing <span class="math inline">\(BC\)</span> is of the order <span class="math inline">\(\mathcal{O}(nm)\)</span>. Let <span class="math inline">\(m=n\)</span>, then to compute <span class="math inline">\(ABC\)</span> has cost of the order <span class="math inline">\(\mathcal{O}(n^3)\)</span> and to compute <span class="math inline">\(A(BC)\)</span> has cost of the order <span class="math inline">\(\mathcal{O}(n^2)\)</span>. Thus, whilst these quantities are the same algebraically, the order of multiplications impacts the number of multiplications and thus impacts the error produced. In the following example we expect computing <span class="math inline">\(ABC\)</span> to have an error approximately <span class="math inline">\(10\)</span> times larger than computing <span class="math inline">\(A(BC)\)</span>.</p><pre class=r><code># check error for matrix addition and subtraction
A &lt;- matrix(rnorm(100),10,10); B &lt;- matrix(rnorm(100),10,10); C &lt;- rnorm(10)
summary(c((A + B) - A - B))</code></pre><pre><code>##       Min.    1st Qu.     Median       Mean    3rd Qu.       Max. 
## -2.220e-16  0.000e+00  0.000e+00  2.559e-18  0.000e+00  2.220e-16</code></pre><pre class=r><code># check error for matrix multiplication
summary(c(A%*%B%*%C - A%*%(B%*%C)))</code></pre><pre><code>##       Min.    1st Qu.     Median       Mean    3rd Qu.       Max. 
## -3.553e-15 -1.554e-15  2.220e-16 -2.776e-16  1.221e-15  1.776e-15</code></pre><pre class=r><code># check computation times
n &lt;- 5000
A &lt;- matrix(rnorm(n^2), n, n); B &lt;- matrix(rnorm(n^2), n, n); C &lt;- rnorm(n)
c(system.time(A%*%B%*%C), system.time(A%*%(B%*%C)))</code></pre><pre><code>##  user.self   sys.self    elapsed user.child  sys.child  user.self   sys.self 
##    107.929      0.083    108.051      0.000      0.000      0.083      0.000 
##    elapsed user.child  sys.child 
##      0.083      0.000      0.000</code></pre><p>When working with matrices we must think carefully about what we are trying to do, in order to avoid unnecessary multiplications which can introduce numerical errors.</p><p>Suppose we want to sum the diagonal entries of the matrix product <span class="math inline">\(AB\)</span>, for <span class="math inline">\(A \in \mathbb{R}^{n \times m}\)</span>, <span class="math inline">\(B \in \mathbb{R}^{m \times n}\)</span> where <span class="math inline">\(m &lt;&lt; n\)</span>. Note the costs of forming <span class="math inline">\(AB\)</span> compared to <span class="math inline">\(BA\)</span> (<span class="math inline">\(\mathcal{O}(n^2m)\)</span> compared to <span class="math inline">\(\mathcal{O}(m^2n)\)</span>). In <code>R</code> there are multiple ways we can do this.</p><ul><li><p>We can compute the matrix product <span class="math inline">\(AB\)</span>, extract the diagonal entries, and sum them.</p></li><li><p>We can instead compute the matrix product <span class="math inline">\(BA\)</span>, extract the diagonal entries, and sum them. This uses the fact that <span class="math inline">\(\text{tr}(AB) = \text{tr}(BA)\)</span>.</p></li><li><p>We can sum the elements of <span class="math inline">\(A * B^T\)</span> (element-wise multiplication), since <span class="math inline">\(\text{tr} = \sum_{i,j} A_{ij} B_{ji}\)</span>.</p></li></ul><pre class=r><code>n &lt;- 10000; m &lt;- 1000
A &lt;- matrix(rnorm(n*m), n, m); B &lt;- matrix(rnorm(n*m), m, n)

# first, second, and third method
first &lt;- sum(diag(A %*% B))
second &lt;- sum(diag(B %*% A))
third &lt;- sum(A * t(B))

# compare errors
summary(first - second)</code></pre><pre><code>##       Min.    1st Qu.     Median       Mean    3rd Qu.       Max. 
## -2.046e-12 -2.046e-12 -2.046e-12 -2.046e-12 -2.046e-12 -2.046e-12</code></pre><pre class=r><code>summary(first - third)</code></pre><pre><code>##       Min.    1st Qu.     Median       Mean    3rd Qu.       Max. 
## -2.274e-12 -2.274e-12 -2.274e-12 -2.274e-12 -2.274e-12 -2.274e-12</code></pre><pre class=r><code>summary(second - third)</code></pre><pre><code>##       Min.    1st Qu.     Median       Mean    3rd Qu.       Max. 
## -2.274e-13 -2.274e-13 -2.274e-13 -2.274e-13 -2.274e-13 -2.274e-13</code></pre><pre class=r><code># compare computation time
system.time(sum(diag(A %*% B))) # first</code></pre><pre><code>##    user  system elapsed 
##  86.641   0.248  86.934</code></pre><pre class=r><code>system.time(sum(diag(B %*% A))) # second</code></pre><pre><code>##    user  system elapsed 
##   8.620   0.020   8.647</code></pre><pre class=r><code>system.time(sum(A * t(B)))      # third</code></pre><pre><code>##    user  system elapsed 
##   0.114   0.024   0.137</code></pre><p>The second method is much better than the first both in terms of precision and run time. The third method is better than the second method.</p></div><div id=sparse-matrices class="section level2"><h2>Sparse Matrices</h2><p>The R packages <code>Matrix</code> provides additional functionality for both dense matrices and sparse matrices. In the <code>Matrix</code> packages, dense matrices are stored as <code>dgeMatrix</code> objects, and sparse matrices are stored as <code>dgCMatrix</code> objects. A useful function we have already seen is <code>rankMatrix</code> which provides the rank of the input matrix up to a certain tolerance.</p><pre class=r><code>library(Matrix)
A &lt;- Matrix(c(1,1,2,2),2,2)
B &lt;- Matrix(c(1,1,2,2) + rnorm(4)/1e10,2,2)

c(rankMatrix(A), rankMatrix(B), rankMatrix(B, tol=1e-7))</code></pre><pre><code>## [1] 1 2 1</code></pre><p>A sparse matrix is one in which most entries are equal to zero. It’s inefficient to store all of these zeros in memory, and so we only store the non-zero entries.</p><pre class=r><code>set.seed(25)
nrows &lt;- ncols &lt;- 500
entries &lt;- sample(c(0,1,2),nrows*ncols,TRUE,c(0.98, 0.01, 0.01))
m1 &lt;- matrix(entries, nrows, ncols)
m2 &lt;- Matrix(entries, nrows, ncols, sparse = TRUE)
c(class(m1), class(m2))</code></pre><pre><code>## [1] &quot;matrix&quot;    &quot;array&quot;     &quot;dgCMatrix&quot;</code></pre><pre class=r><code>m1[1:2,1:10]</code></pre><pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
## [1,]    0    0    0    0    0    0    0    0    0     0
## [2,]    0    1    0    0    0    0    0    0    0     1</code></pre><pre class=r><code>m2[1:2,1:10]</code></pre><pre><code>## 2 x 10 sparse Matrix of class &quot;dgCMatrix&quot;
##                         
## [1,] . . . . . . . . . .
## [2,] . 1 . . . . . . . 1</code></pre><pre class=r><code>c(object.size(m1), object.size(m2))</code></pre><pre><code>## [1] 2000216   62904</code></pre><p>We see that a sparse matrix defined using the <code>Matrix</code> package has class <code>dgCMatrix</code>. The ‘d’ stands for digit, the ‘g’ stands for general, and the ‘C’ stands for column. We can convert a <code>dgCMatrix</code> to a <code>dgeMatrix</code> — the standard class for dense matrices — but we will lose the memory improvements of the compressed sparse format. Alternatives to the <code>dgCMatrix</code> are the <code>dgRMatrix</code> and <code>dgTMatrix</code> classes. We can convert a <code>dgCMatrix</code> into a <code>dgTMatrix</code> (a triplet matrix), but not a <code>dgRMatrix</code>.</p><pre class=r><code># display the structure
str(m2, max.level = 1)</code></pre><pre><code>## Formal class &#39;dgCMatrix&#39; [package &quot;Matrix&quot;] with 6 slots</code></pre><pre class=r><code>str(m2)</code></pre><pre><code>## Formal class &#39;dgCMatrix&#39; [package &quot;Matrix&quot;] with 6 slots
##   ..@ i       : int [1:4950] 5 46 141 211 315 327 380 430 482 485 ...
##   ..@ p       : int [1:501] 0 10 21 29 42 47 54 58 67 76 ...
##   ..@ Dim     : int [1:2] 500 500
##   ..@ Dimnames:List of 2
##   .. ..$ : NULL
##   .. ..$ : NULL
##   ..@ x       : num [1:4950] 2 1 1 1 1 1 1 1 1 1 ...
##   ..@ factors : list()</code></pre><pre class=r><code>which(m2[,1]&gt;0)</code></pre><pre><code>##  [1]   6  47 142 212 316 328 381 431 483 486</code></pre><pre class=r><code># show difference in memory size
object.size(as(m2, &#39;dgeMatrix&#39;))</code></pre><pre><code>## as(&lt;dgCMatrix&gt;, &quot;dgeMatrix&quot;) is deprecated since Matrix 1.5-0; do as(., &quot;unpackedMatrix&quot;) instead</code></pre><pre><code>## 2001176 bytes</code></pre><pre class=r><code>object.size(as(m2, &#39;dgTMatrix&#39;))</code></pre><pre><code>## 80696 bytes</code></pre><pre class=r><code>object.size(m2) # dgCMatrix</code></pre><pre><code>## 62904 bytes</code></pre><pre class=r><code># print the matrices before and after coercion
m2[1:2, 1:10] </code></pre><pre><code>## 2 x 10 sparse Matrix of class &quot;dgCMatrix&quot;
##                         
## [1,] . . . . . . . . . .
## [2,] . 1 . . . . . . . 1</code></pre><pre class=r><code>as(m2, &#39;dgTMatrix&#39;)[1:2, 1:10]</code></pre><pre><code>## 2 x 10 sparse Matrix of class &quot;dgTMatrix&quot;
##                         
## [1,] . . . . . . . . . .
## [2,] . 1 . . . . . . . 1</code></pre><div id=operations-for-sparse-matrices class="section level3"><h3>Operations for sparse matrices</h3><pre class=r><code>A &lt;- B &lt;- Matrix(c(1,1,0,0,0,1),3,2, sparse=TRUE)
A</code></pre><pre><code>## 3 x 2 sparse Matrix of class &quot;dgCMatrix&quot;
##         
## [1,] 1 .
## [2,] 1 .
## [3,] . 1</code></pre><pre class=r><code># division maintains class
A/10</code></pre><pre><code>## 3 x 2 sparse Matrix of class &quot;dgCMatrix&quot;
##             
## [1,] 0.1 .  
## [2,] 0.1 .  
## [3,] .   0.1</code></pre><pre class=r><code># addition and subtraction change class to dgeMatrix
A+1; A-1</code></pre><pre><code>## 3 x 2 Matrix of class &quot;dgeMatrix&quot;
##      [,1] [,2]
## [1,]    2    1
## [2,]    2    1
## [3,]    1    2</code></pre><pre><code>## 3 x 2 Matrix of class &quot;dgeMatrix&quot;
##      [,1] [,2]
## [1,]    0   -1
## [2,]    0   -1
## [3,]   -1    0</code></pre><pre class=r><code># matrix multiplication changes class
A %*% c(1,1)</code></pre><pre><code>## 3 x 1 Matrix of class &quot;dgeMatrix&quot;
##      [,1]
## [1,]    1
## [2,]    1
## [3,]    1</code></pre><pre class=r><code># addition and subtraction of two dgCMatrix objects produces an object of the same class
A+B; A-B</code></pre><pre><code>## 3 x 2 sparse Matrix of class &quot;dgCMatrix&quot;
##         
## [1,] 2 .
## [2,] 2 .
## [3,] . 2</code></pre><pre><code>## 3 x 2 sparse Matrix of class &quot;dgCMatrix&quot;
##         
## [1,] 0 .
## [2,] 0 .
## [3,] . 0</code></pre><pre class=r><code># matrix multiplication of two dgCMatrix objects gives a dgCMatrix object
A %*% t(B)</code></pre><pre><code>## 3 x 3 sparse Matrix of class &quot;dgCMatrix&quot;
##           
## [1,] 1 1 .
## [2,] 1 1 .
## [3,] . . 1</code></pre><pre class=r><code># row or column binding dgCMatrix objects returns a dgCMatrix
cbind(A,A); rbind(A,A)</code></pre><pre><code>## 3 x 4 sparse Matrix of class &quot;dgCMatrix&quot;
##             
## [1,] 1 . 1 .
## [2,] 1 . 1 .
## [3,] . 1 . 1</code></pre><pre><code>## 6 x 2 sparse Matrix of class &quot;dgCMatrix&quot;
##         
## [1,] 1 .
## [2,] 1 .
## [3,] . 1
## [4,] 1 .
## [5,] 1 .
## [6,] . 1</code></pre></div><div id=solving-large-linear-systems class="section level3"><h3>Solving large linear systems</h3><p>Solving linear systems for very large and sparse systems is very difficult, as the inverse of a sparse matrix is not necessarily sparse. To avoid these problems we should directly solve the linear system using <code>solve(A, b)</code>.</p><pre class=r><code>nrow &lt;- ncol &lt;- 500
A &lt;- Matrix(sample(c(0,1), nrow*ncol, TRUE, c(0.98, 0.02)), nrow, ncol, sparse=TRUE)
A.inv &lt;- solve(A)

# object sizes
c(object.size(A), object.size(A.inv))</code></pre><pre><code>## [1] 1884440 2001176</code></pre><pre class=r><code># possible elements
nrow*ncol</code></pre><pre><code>## [1] 250000</code></pre><pre class=r><code># entries in A
nnzero(A)</code></pre><pre><code>## [1] 4897</code></pre><pre class=r><code># entries in A.inv
nnzero(A.inv)</code></pre><pre><code>## [1] 250000</code></pre></div></div></div></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://jakespiteri.co.uk/portfolio/computing-1/report-7/><span class=title>« Prev</span><br><span>Portfolio Report 7: Debugging and Performance</span></a>
<a class=next href=https://jakespiteri.co.uk/portfolio/computing-1/report-9/><span class=title>Next »</span><br><span>Portfolio Report 9: Numerical Optimization</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://jakespiteri.co.uk/>Jake Spiteri</a></span>
<span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>