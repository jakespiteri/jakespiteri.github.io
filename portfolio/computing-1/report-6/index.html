<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Portfolio Report 6: Tidyverse | Jake Spiteri</title><meta name=keywords content><meta name=description content="Tidyverse The Tidyverse is a set of inter-compatible packages that are used throughout data science. The Tidyverse provides powerful tools that allow us to quickly `tidy’ data into data frames, transform the data, and then visualize it. This will then allow us to produce models. Throughout this report we will explore a real dataset found on Kaggle.
Pipes The pipe operator %>% is provided by the magrittr R package. Pipes are a powerful tool that allow us to clearly express a sequence of operations."><meta name=author content="Jake Spiteri"><link rel=canonical href=https://jakespiteri.co.uk/portfolio/computing-1/report-6/><meta name=google-site-verification content="XYZabc"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css integrity=sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js integrity=sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link crossorigin=anonymous href=/assets/css/stylesheet.ccdd7c01ba69b30dd10ab397e0d0f0774c08df41d39f6b53e16f862223c92b98.css integrity="sha256-zN18Abppsw3RCrOX4NDwd0wI30HTn2tT4W+GIiPJK5g=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://jakespiteri.co.uk/favi.png><link rel=icon type=image/png sizes=16x16 href=https://jakespiteri.co.uk/favi.png><link rel=icon type=image/png sizes=32x32 href=https://jakespiteri.co.uk/favi.png><link rel=apple-touch-icon href=https://jakespiteri.co.uk/favi.png><link rel=mask-icon href=https://jakespiteri.co.uk/favi.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Portfolio Report 6: Tidyverse"><meta property="og:description" content="Tidyverse The Tidyverse is a set of inter-compatible packages that are used throughout data science. The Tidyverse provides powerful tools that allow us to quickly `tidy’ data into data frames, transform the data, and then visualize it. This will then allow us to produce models. Throughout this report we will explore a real dataset found on Kaggle.
Pipes The pipe operator %>% is provided by the magrittr R package. Pipes are a powerful tool that allow us to clearly express a sequence of operations."><meta property="og:type" content="article"><meta property="og:url" content="https://jakespiteri.co.uk/portfolio/computing-1/report-6/"><meta property="og:image" content="https://jakespiteri.co.uk/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="portfolio"><meta property="og:site_name" content="Jake Spiteri"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jakespiteri.co.uk/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Portfolio Report 6: Tidyverse"><meta name=twitter:description content="Tidyverse The Tidyverse is a set of inter-compatible packages that are used throughout data science. The Tidyverse provides powerful tools that allow us to quickly `tidy’ data into data frames, transform the data, and then visualize it. This will then allow us to produce models. Throughout this report we will explore a real dataset found on Kaggle.
Pipes The pipe operator %>% is provided by the magrittr R package. Pipes are a powerful tool that allow us to clearly express a sequence of operations."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Portfolio","item":"https://jakespiteri.co.uk/portfolio/"},{"@type":"ListItem","position":2,"name":"Statistical Computing 1","item":"https://jakespiteri.co.uk/portfolio/computing-1/"},{"@type":"ListItem","position":3,"name":"Portfolio Report 6: Tidyverse","item":"https://jakespiteri.co.uk/portfolio/computing-1/report-6/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Portfolio Report 6: Tidyverse","name":"Portfolio Report 6: Tidyverse","description":"Tidyverse The Tidyverse is a set of inter-compatible packages that are used throughout data science. The Tidyverse provides powerful tools that allow us to quickly `tidy’ data into data frames, transform the data, and then visualize it. This will then allow us to produce models. Throughout this report we will explore a real dataset found on Kaggle.\nPipes The pipe operator %\u0026gt;% is provided by the magrittr R package. Pipes are a powerful tool that allow us to clearly express a sequence of operations.","keywords":[],"articleBody":" Tidyverse The Tidyverse is a set of inter-compatible packages that are used throughout data science. The Tidyverse provides powerful tools that allow us to quickly `tidy’ data into data frames, transform the data, and then visualize it. This will then allow us to produce models. Throughout this report we will explore a real dataset found on Kaggle.\nPipes The pipe operator %\u003e% is provided by the magrittr R package. Pipes are a powerful tool that allow us to clearly express a sequence of operations. It may be intuitive to read the operator %\u003e% as ‘piped into’. Thus we would read a_R_object %\u003e% a_function as ‘a R object is piped into a function’. The general idea is that g(f(x)) can be rewritten as x %\u003e% f %\u003e% g. This is particularly useful when we are transforming data and want to sequentially make changes. Below we write two versions of the same code, one which uses pipes and one which uses traditional R programming.\nFirst we import the tidyverse.\nlibrary(tidyverse) # setup par(mfrow=c(1,2)) x \u003c- seq(0,10, length.out=1000) # normal R programming plot(sqrt(abs(cos(x)))) # with the piping operator x %\u003e% cos %\u003e% abs %\u003e% sqrt %\u003e% plot Note that in this case the piping operator is less clear. Note the y label in the above graph. It is . because the piping operator’s partial results are stored in .. We can also use the . to tell the piping operator where to pipe your variable into. For example, we may have a function with two inputs.\n# function with two inputs cust_add \u003c- function(x1,x2) { return(x1+2*(x2)) } # define a sequence x \u003c- seq(0,1,length.out = 10) # pipe x into the second element of cust_add() x %\u003e% cust_add(1, .) ## [1] 1.000000 1.222222 1.444444 1.666667 1.888889 2.111111 2.333333 2.555556 ## [9] 2.777778 3.000000 # sanity check cust_add(1,x) == x %\u003e% cust_add(1, .) ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE It is worth noting that by default, the piping operator pipes into the first input of a function, so x %\u003e% function(y) becomes function(x,y).\nWe now look at an example with the dataset UKload. An example with data is perhaps the best way to demonstrate the power of pipes.\ndata(UKload) head(UKload) ## NetDemand wM wM_s95 Posan Dow Trend NetDemand.48 ## 25 38353 6.046364 5.558800 0.001369941 samedi 1293879600 38353 ## 73 41192 2.803969 3.230582 0.004109824 dimanche 1293966000 38353 ## 121 43442 2.097259 1.858198 0.006849706 lundi 1294052400 41192 ## 169 50736 3.444187 2.310408 0.009589588 mardi 1294138800 43442 ## 217 50438 5.958674 4.724961 0.012329471 mercredi 1294225200 50736 ## 265 50064 4.124248 4.589470 0.015069353 jeudi 1294311600 50438 ## Holy Year Date ## 25 1 2011 2011-01-01 12:00:00 ## 73 0 2011 2011-01-02 12:00:00 ## 121 0 2011 2011-01-03 12:00:00 ## 169 0 2011 2011-01-04 12:00:00 ## 217 0 2011 2011-01-05 12:00:00 ## 265 0 2011 2011-01-06 12:00:00 Pipes make transforming the data via a sequence of operations simple, and easy to read.\n# setup plot par(mfrow=c(1,2)) # look at transformed data for lundi UKload %\u003e% subset(Dow == \"lundi\", select = c(\"NetDemand\", \"Posan\")) %\u003e% head(100) %\u003e% transform(Posan = Posan * 365) %\u003e% glimpse ## Rows: 100 ## Columns: 2 ## $ NetDemand 43442, 50645, 48105, 49792, 51282, 47985, 46741, 50163, 4840… ## $ Posan 2.500143, 9.500542, 16.500942, 23.501341, 30.501741, 37.5021… # lundi UKload %\u003e% subset(Dow == \"lundi\", select = c(\"NetDemand\", \"Posan\")) %\u003e% head(100) %\u003e% transform(Posan = Posan * 365) %\u003e% plot(NetDemand ~ Posan, data = ., ylim=c(33000,53000), main = \"Net energy demand on Mondays\", xlab = \"Day in year\", ylab = \"Net demand\") # samedi UKload %\u003e% subset(Dow == \"samedi\", select = c(\"NetDemand\", \"Posan\")) %\u003e% head(100) %\u003e% transform(Posan = Posan * 365) %\u003e% plot(NetDemand ~ Posan, data = ., ylim=c(33000,53000), main = \"Net energy demand on Saturdays\", xlab = \"Day in year\", ylab = \"Net demand\") Advanced piping There are other types of operators with specific properties. Note that you may need to import the library magrittr after importing the Tidyverse in order to use advanced pipes.\nThe assignment pipe %\u003c\u003e% The operator %\u003c\u003e% works the same as the classic pipe %\u003e%, but it also assigns the transformation to the original object. We can see this below.\nx \u003c- seq(0,1,length.out=5) print(x) ## [1] 0.00 0.25 0.50 0.75 1.00 x %\u003c\u003e% rev print(x) ## [1] 1.00 0.75 0.50 0.25 0.00 The tee pipe %T\u003e% We may want to store the output of our sequence of operations. We can often do this via the assignment operator, but we often pipe our output into the plot function. In this case, we cannot use the assignment operator as seen below.\ns \u003c- seq(0,10,length.out=100) s %\u003c\u003e% cos %\u003e% plot print(s) ## NULL We see that \\(s\\) is NULL. Instead we may store the output in the middle of a sequence of pipes by using the tee operator %T\u003e% as seen below. We begin the pipe with the assignment operator \u003c-. Note that \\(s\\) now stores the output of the \\(cos()\\) function.\npar(mfrow=c(1,2)) s \u003c- seq(0,10,length.out=100) s \u003c- s %\u003e% cos %T\u003e% plot plot(s) print(s[1:5]) ## [1] 1.0000000 0.9949028 0.9796632 0.9544366 0.9194801 The exposition pipe %$% When using pipes, we may encounter a scenario in which we want the names on the left hand side of the pipe to be easily available to the right hand side. This is what the exposition pipe does. This is particularly useful when working with named data and lists. Below we work with the UKload dataset for an example.\nhead(UKload) ## NetDemand wM wM_s95 Posan Dow Trend NetDemand.48 ## 25 38353 6.046364 5.558800 0.001369941 samedi 1293879600 38353 ## 73 41192 2.803969 3.230582 0.004109824 dimanche 1293966000 38353 ## 121 43442 2.097259 1.858198 0.006849706 lundi 1294052400 41192 ## 169 50736 3.444187 2.310408 0.009589588 mardi 1294138800 43442 ## 217 50438 5.958674 4.724961 0.012329471 mercredi 1294225200 50736 ## 265 50064 4.124248 4.589470 0.015069353 jeudi 1294311600 50438 ## Holy Year Date ## 25 1 2011 2011-01-01 12:00:00 ## 73 0 2011 2011-01-02 12:00:00 ## 121 0 2011 2011-01-03 12:00:00 ## 169 0 2011 2011-01-04 12:00:00 ## 217 0 2011 2011-01-05 12:00:00 ## 265 0 2011 2011-01-06 12:00:00 UKload %\u003e% subset(Year == 2011) %$% cor(wM, NetDemand) ## [1] -0.6858647 Without the exposition pipe this would be done in the following way.\nUKload %\u003e% subset(Year == 2011) %\u003e% {cor(.$wM, .$NetDemand)} ## [1] -0.6858647 Visualizations with ggplot2 We will use ggplot2 for an exploratory analysis of the ASHRAE - Great Energy Predictor III dataset found here on Kaggle.\nData setup # set the seed for reproducibility set.seed(1) # load the whole dataset data_train \u003c- read.csv(\"~/Downloads/energy_data/train.csv\") # inspect head(data_train); dim(data_train) # we load the other files and join them into one data frame building_data \u003c- read.csv(\"~/Downloads/energy_data/building_metadata.csv\") weather_train \u003c- read.csv(\"~/Downloads/energy_data/weather_train.csv\") # join the data together all_train \u003c- data_train %\u003e% left_join(building_data, by = \"building_id\") %\u003e% left_join(weather_train, by = c(\"site_id\", \"timestamp\")) # check memory size all_train %\u003e% object.size %\u003e% format(units = \"MB\") # we see that although building_metadata.csv, and weather_train.csv are very small files # the combined data frame has size approx 1850Mb # so we only keep a subset to work with # keep only a subset of the dataset nlevels(as.factor(all_train$building_id)) data_subset \u003c- all_train %\u003e% filter(building_id %in% sample(1449, 150)) head(data_subset) # let's save this data so we don't have to import the full dataset again write.csv(data_subset, \"~/Downloads/energy_data/subset_combined_train.csv\") The above code combined the multiple files, and saves a subset of the combined training data. The full dataset (1449 building_ids) has approximate size 1850Mb whereas the subset of 150 building_ids only uses 1.4b of memory. To avoid the unnecessary memory usage in the above step, the code has been ran once and the subset had been written to a .csv file.\nIntro to ggplot2 Let’s import the dataset data_subset and add some useful variables such as the day, hour, etc.\n# import the dataset data_subset \u003c- read.csv(\"~/Downloads/energy_data/subset_combined_train.csv\") # create new feature variables based on the date/time data_subset \u003c- data_subset %\u003e% mutate(timestamp_ymd_hms = ymd_hms(timestamp), timestamp_hour = factor(hour(timestamp_ymd_hms)), timestamp_day = factor(day(timestamp_ymd_hms)), timestamp_week = factor(week(timestamp_ymd_hms)), timestamp_month = factor(month(timestamp_ymd_hms, label=TRUE)), timestamp_year = factor(year(timestamp_ymd_hms)), meter = factor(meter) ) # for basic plots small_data_subset \u003c- data_subset %\u003e% subset(timestamp_month %in% c(\"Jun\", \"Nov\")) %\u003e% group_by(timestamp_hour, timestamp_month) %\u003e% summarise(avg_meter_reading = median(meter_reading)) ## `summarise()` has grouped output by 'timestamp_hour'. You can override using ## the `.groups` argument. In the above example we see that functions provided by the tidyverse make code much neater and easier to write. Feature engineering becomes simpler with functions such as group_by(). We now start from the basics and build plots with ggplot2.\nBase R plots are called for their side effects rather than the returned value. When calling plot we indeed produce a plot, but the function doesn’t return anything of value. This is quite different to ggplot2 in which we create and store a ggplot object, which we then call to produce a plot.\nWhen using ggplot we add multiple layers to the plot. We initially create the plot object, which creates a blank canvas. We may then add a scatterplot or histogram layer. If we then wanted to add a title or legend, we would add these to our ggplot object.\nCalling ggplot defines a blank canvas. We can then add a scatter plot to the canvas.\n# first plot plot1 \u003c- ggplot(data = small_data_subset) + theme_bw() # second plot plot2 \u003c- plot1 + geom_point(aes(x = timestamp_hour, y = avg_meter_reading, col=timestamp_month)) # plot both grid.arrange(plot1, plot2, ncol=2) # using gridExtra package When evaluating an object, R calls the generic print function. As our object has class ggplot, R calls the print.ggplot function. The main difference between ggplot2 and graphics plotting methods is that gplot2 separates the plot-building phase (defining a ggplot object and then adding layers) from the rendering phase (calling the print function).\nA general template for creating a ggplot may look like:\nggplot(data = ) + (mapping = aes()) In this template\nggplot creates a ggplot object, with a data.frame as its main argument. + is an overloaded operator. On the left hand side we have a ggplot object, and on the right hand side is a layer or function that modifies the plot. is a graphical layer, such as geom_point. Each layer needs a mapping. We may be interested in the energy usage of new and modern buildings vs older buildings. To gain some insight we use dplyr‘s mutate to create a new factor variable denoting whether the building is ’Old’ or ‘Modern’. To do this we use two approaches: one in which buildings older than the median building age are considered old and those newer are considered to be modern. Another approach is to define buildings built after the year 2000 to be modern and before 2000 to be old.\ndata_subset %\u003c\u003e% mutate(building_age_med = factor(as.logical(year_built \u003e median(year_built, na.rm=TRUE)), labels = c(\"Modern\", \"Old\"))) data_subset %\u003c\u003e% mutate(building_age_2 = factor((year_built \u003e 2000), labels = c(\"Modern\", \"Old\"))) data_subset %\u003e% select(year_built, building_age_med, building_age_2) %\u003e% head() ## year_built building_age_med building_age_2 ## 1 2004 Old Old ## 2 1996 Old Modern ## 3 2002 Old Old ## 4 1969 Old Modern ## 5 2001 Old Old ## 6 1986 Old Modern We then use dplyr and ggplot2 to plot a graph.\n# create data for building_age_med data_subset_1 \u003c- data_subset %\u003e% filter(!is.na(building_age_med)) %\u003e% group_by(building_age_med, timestamp_hour) %\u003e% summarise(median_reading = median(meter_reading, na.rm=TRUE)) %\u003e% mutate(building_age_type = \"Median\") %\u003e% dplyr::rename(building_age = building_age_med) ## `summarise()` has grouped output by 'building_age_med'. You can override using ## the `.groups` argument. # create subset of data for building_age_2 i.e. \u003e2000 or \u003c2000 data_subset_2 \u003c- data_subset %\u003e% filter(!is.na(building_age_2)) %\u003e% group_by(building_age_2, timestamp_hour) %\u003e% summarise(median_reading = median(meter_reading, na.rm=TRUE)) %\u003e% mutate(building_age_type = \"\u003e2000\") %\u003e% dplyr::rename(building_age = building_age_2) ## `summarise()` has grouped output by 'building_age_2'. You can override using ## the `.groups` argument. data_subset_comb \u003c- bind_rows(data_subset_1, data_subset_2, id=NULL) data_subset_comb$building_age_type \u003c- factor(data_subset_comb$building_age_type, labels=c(\"\u003e2000\", \"Median\")) data_subset_comb %\u003e% filter(!is.na(building_age)) %\u003e% ggplot(aes(x=as.numeric(timestamp_hour), y=median_reading, col=building_age)) + facet_wrap(vars(building_age_type)) + geom_line() We clearly see on both facets that modern houses use less energy than old buildings In the left we see that energy usage increases dramatically around 1000 and decreases around 1400. This may imply that older buildings are less insulated than modern buildings, hence the need for heating the building throughout the day. We split the building age into decades below to further inspect the data.\ndata_subset \u003c- data_subset %\u003e% mutate(decade_built = as.factor(floor((year_built)/10)*10)) data_subset %\u003e% filter(timestamp_month == \"Jan\") %\u003e% select(decade_built, timestamp_hour, meter_reading) %\u003e% filter(!is.na(decade_built), decade_built %in% seq(1950,2010,10)) %\u003e% group_by(decade_built, timestamp_hour) %\u003e% summarise(median_reading = median(meter_reading, na.rm=TRUE)) %\u003e% ggplot(aes(x=as.numeric(timestamp_hour), y=median_reading, col=decade_built)) + geom_line() ## `summarise()` has grouped output by 'decade_built'. You can override using the ## `.groups` argument. This isn’t exactly what we expected, but it’s likely that there are higher-dimensional relationships within the data which we simply cannot capture with a 2D graph. There are many more factors which impact the average meter reading.\nWe may be interested in the median readings of different types of meter.\ndata_subset$meter \u003c- factor(data_subset$meter, levels = 0:3) data_subset %\u003e% group_by(meter) %\u003e% ggplot(aes(x = log(meter_reading + 1), fill = meter)) + geom_density(alpha=0.4, adjust=1.5) + scale_fill_discrete() Let’s plot the median meter reading for each hour of the day.\ndata_subset %\u003e% group_by(timestamp_hour) %\u003e% summarise(median_meter_reading = median(meter_reading)) %\u003e% ggplot(aes(x=timestamp_hour, y=median_meter_reading)) + geom_point() + geom_smooth() ## `geom_smooth()` using method = 'loess' and formula 'y ~ x' We may be interested in a plot of median meter readings for each type of building in primary_use.\ndata_subset %\u003e% group_by(timestamp_hour, primary_use) %\u003e% summarise(median_meter_reading = median(meter_reading)) %\u003e% ggplot(aes(x = as.numeric(timestamp_hour), y = median_meter_reading)) + geom_line(colour = \"skyblue\") + facet_wrap(vars(primary_use), scales=\"free\") + theme_minimal() + labs(title = \"Median meter reading over the day\", subtitle = \"For different building uses\", x = \"Hour of the day\", y = \"Average median reading\") ## `summarise()` has grouped output by 'timestamp_hour'. You can override using ## the `.groups` argument. ggplot offers some nice tools for visualizing correlation matrices.\n# get the correlation matrix corrmat \u003c- data_subset %\u003e% select(-site_id) %\u003e% select_if(is.numeric) %\u003e% drop_na() %\u003e% {round(cor(.),2)} # melt into long format ready for ggplot2 corrlong \u003c- melt(corrmat) ## Warning in type.convert.default(X[[i]], ...): 'as.is' should be specified by the ## caller; using TRUE ## Warning in type.convert.default(X[[i]], ...): 'as.is' should be specified by the ## caller; using TRUE # plot with ggplot2 plot1 \u003c- corrlong %\u003e% ggplot(aes(x=X1, y=X2, fill = value)) + geom_tile() + labs(title = \"Matrix of variable correlations\", x = \"\", y = \"\") + theme(axis.text.x = element_text(angle=90, hjust=1)) # plot only correlations with meter_reading corrlong$X1 \u003c- factor(corrlong$X1) plot2 \u003c- corrlong %\u003e% filter(X2 == \"meter_reading\") %\u003e% select(X1, value) %\u003e% as.data.frame() %\u003e% ggplot(aes(x = reorder(X1, value), y = value)) + geom_col() + coord_flip() + labs(title = \"Correlation of factors with meter reading\", x=\"\", y=\"Correlation\") grid.arrange(plot1, plot2, ncol=2) We are mostly interested in the factors which affect the meter reading. The above correlation matrix tells us that meter_reading is positively correlated with square_feet and floor_count. Let’s produce some plots to see the relationship.\ndata_subset %\u003e% filter(square_feet \u003c= 4e+05, timestamp_month == c(\"Jun\")) %\u003e% group_by(building_id, meter) %\u003e% summarise(avg_meter_reading = median(meter_reading), square_feet = mean(square_feet)) %\u003e% ggplot(aes(x=square_feet, y=avg_meter_reading)) + geom_point() + geom_smooth(method=\"glm\") + labs(title = \"Average meter readings in June\", subtitle = \"GLM overlaid in blue\", y = \"Average meter reading\", x = \"Square feet\") ## `summarise()` has grouped output by 'building_id'. You can override using the ## `.groups` argument. ## `geom_smooth()` using formula 'y ~ x' data_subset %\u003e% filter(building_id != 685, building_id != 803, # remove outliers timestamp_month %in% c(\"Jun\"), !is.na(floor_count)) %\u003e% group_by(floor_count) %\u003e% summarise(avg_meter_reading = median(meter_reading)) %\u003e% ggplot(aes(x=floor_count, y=avg_meter_reading)) + geom_col() + labs(title = \"Average meter readings in June\", y = \"Average meter reading\", x = \"Number of floors\") The graph seems to make sense. As the number of floors increases, the amount of energy needed to heat the building increases. There were some outliers which have to be removed such as the building with id \\(685\\) which has 5 floors and approximately \\(250,000\\) square feet! It uses much more energy than we would expect.\n","wordCount":"2610","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Jake Spiteri"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://jakespiteri.co.uk/portfolio/computing-1/report-6/"},"publisher":{"@type":"Organization","name":"Jake Spiteri","logo":{"@type":"ImageObject","url":"https://jakespiteri.co.uk/favi.png"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://jakespiteri.co.uk/ accesskey=h title="Home (Alt + H)"><div class=custom-logo><span class=logo__mark></span>
<span class=logo__text>>$ cd /home</span>
<span class=logo__cursor style=background-color:#1290ff></span></div></a><div class=logo-switches></div></div><ul id=menu style=font-family:monospace,monospace><li><a href=https://jakespiteri.co.uk/about/ title=/about><span>/about</span></a></li><li><a href=https://jakespiteri.co.uk/portfolio/ title=/portfolio><span>/portfolio</span></a></li><li><a href=https://jakespiteri.co.uk/blog/ title=/blog><span>/blog</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://jakespiteri.co.uk/>Home</a>&nbsp;»&nbsp;<a href=https://jakespiteri.co.uk/portfolio/>Portfolio</a>&nbsp;»&nbsp;<a href=https://jakespiteri.co.uk/portfolio/computing-1/>Statistical Computing 1</a></div><h1 class=post-title>Portfolio Report 6: Tidyverse</h1><div class=post-meta>Jake Spiteri&nbsp;|&nbsp;<a href=https://github.com/jakespiteri/jakespiteri.github.io/tree/master/portfolio/computing-1/report-6/index.Rmd rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><div id=tidyverse class="section level1"><h1>Tidyverse</h1><p>The Tidyverse is a set of inter-compatible packages that are used throughout data science. The Tidyverse provides powerful tools that allow us to quickly `tidy’ data into data frames, transform the data, and then visualize it. This will then allow us to produce models. Throughout this report we will explore a real dataset found on Kaggle.</p><div id=pipes class="section level2"><h2>Pipes</h2><p>The pipe operator <code>%>%</code> is provided by the <code>magrittr</code> R package. Pipes are a powerful tool that allow us to clearly express a sequence of operations. It may be intuitive to read the operator <code>%>%</code> as ‘piped into’. Thus we would read <code>a_R_object %>% a_function</code> as ‘a R object is piped into a function’. The general idea is that <code>g(f(x))</code> can be rewritten as <code>x %>% f %>% g</code>. This is particularly useful when we are transforming data and want to sequentially make changes. Below we write two versions of the same code, one which uses pipes and one which uses traditional R programming.</p><p>First we import the tidyverse.</p><pre class=r><code>library(tidyverse)</code></pre><pre class=r><code># setup
par(mfrow=c(1,2))
x &lt;- seq(0,10, length.out=1000)

# normal R programming
plot(sqrt(abs(cos(x))))

# with the piping operator
x %&gt;% cos %&gt;% abs %&gt;% sqrt %&gt;% plot</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-2-1.png width=1344 style=display:block;margin:auto>
Note that in this case the piping operator is <em>less</em> clear. Note the y label in the above graph. It is <code>.</code> because the piping operator’s partial results are stored in <code>.</code>. We can also use the <code>.</code> to tell the piping operator where to pipe your variable into. For example, we may have a function with two inputs.</p><pre class=r><code># function with two inputs
cust_add &lt;- function(x1,x2) {
  return(x1+2*(x2))
}

# define a sequence
x &lt;- seq(0,1,length.out = 10)

# pipe x into the second element of cust_add()
x %&gt;% cust_add(1, .)</code></pre><pre><code>##  [1] 1.000000 1.222222 1.444444 1.666667 1.888889 2.111111 2.333333 2.555556
##  [9] 2.777778 3.000000</code></pre><pre class=r><code># sanity check
cust_add(1,x) == x %&gt;% cust_add(1, .)</code></pre><pre><code>##  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE</code></pre><p>It is worth noting that by default, the piping operator pipes into the first input of a function, so <code>x %>% function(y)</code> becomes <code>function(x,y)</code>.</p><p>We now look at an example with the dataset UKload. An example with data is perhaps the best way to demonstrate the power of pipes.</p><pre class=r><code>data(UKload)
head(UKload)</code></pre><pre><code>##     NetDemand       wM   wM_s95       Posan      Dow      Trend NetDemand.48
## 25      38353 6.046364 5.558800 0.001369941   samedi 1293879600        38353
## 73      41192 2.803969 3.230582 0.004109824 dimanche 1293966000        38353
## 121     43442 2.097259 1.858198 0.006849706    lundi 1294052400        41192
## 169     50736 3.444187 2.310408 0.009589588    mardi 1294138800        43442
## 217     50438 5.958674 4.724961 0.012329471 mercredi 1294225200        50736
## 265     50064 4.124248 4.589470 0.015069353    jeudi 1294311600        50438
##     Holy Year                Date
## 25     1 2011 2011-01-01 12:00:00
## 73     0 2011 2011-01-02 12:00:00
## 121    0 2011 2011-01-03 12:00:00
## 169    0 2011 2011-01-04 12:00:00
## 217    0 2011 2011-01-05 12:00:00
## 265    0 2011 2011-01-06 12:00:00</code></pre><p>Pipes make transforming the data via a sequence of operations simple, and easy to read.</p><pre class=r><code># setup plot
par(mfrow=c(1,2))

# look at transformed data for lundi
UKload %&gt;%
  subset(Dow == &quot;lundi&quot;, select = c(&quot;NetDemand&quot;, &quot;Posan&quot;)) %&gt;%
  head(100) %&gt;%
  transform(Posan = Posan * 365) %&gt;%
  glimpse</code></pre><pre><code>## Rows: 100
## Columns: 2
## $ NetDemand &lt;dbl&gt; 43442, 50645, 48105, 49792, 51282, 47985, 46741, 50163, 4840…
## $ Posan     &lt;dbl&gt; 2.500143, 9.500542, 16.500942, 23.501341, 30.501741, 37.5021…</code></pre><pre class=r><code># lundi
UKload %&gt;%
  subset(Dow == &quot;lundi&quot;, select = c(&quot;NetDemand&quot;, &quot;Posan&quot;)) %&gt;%
  head(100) %&gt;%
  transform(Posan = Posan * 365) %&gt;%
  plot(NetDemand ~ Posan, data = ., ylim=c(33000,53000),
       main = &quot;Net energy demand on Mondays&quot;, xlab = &quot;Day in year&quot;, ylab = &quot;Net demand&quot;)

# samedi
UKload %&gt;%
  subset(Dow == &quot;samedi&quot;, select = c(&quot;NetDemand&quot;, &quot;Posan&quot;)) %&gt;%
  head(100) %&gt;%
  transform(Posan = Posan * 365) %&gt;%
  plot(NetDemand ~ Posan, data = ., ylim=c(33000,53000),
       main = &quot;Net energy demand on Saturdays&quot;, xlab = &quot;Day in year&quot;, ylab = &quot;Net demand&quot;)</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-5-1.png width=1344 style=display:block;margin:auto></p></div><div id=advanced-piping class="section level2"><h2>Advanced piping</h2><p>There are other types of operators with specific properties. Note that you may need to import the library <code>magrittr</code> after importing the Tidyverse in order to use advanced pipes.</p><div id=the-assignment-pipe class="section level3"><h3>The assignment pipe <code>%&lt;>%</code></h3><p>The operator <code>%&lt;>%</code> works the same as the classic pipe <code>%>%</code>, but it also assigns the transformation to the original object. We can see this below.</p><pre class=r><code>x &lt;- seq(0,1,length.out=5)
print(x)</code></pre><pre><code>## [1] 0.00 0.25 0.50 0.75 1.00</code></pre><pre class=r><code>x %&lt;&gt;% rev
print(x)</code></pre><pre><code>## [1] 1.00 0.75 0.50 0.25 0.00</code></pre></div><div id=the-tee-pipe-t class="section level3"><h3>The <code>tee</code> pipe <code>%T>%</code></h3><p>We may want to store the output of our sequence of operations. We can often do this via the assignment operator, but we often pipe our output into the <code>plot</code> function. In this case, we cannot use the assignment operator as seen below.</p><pre class=r><code>s &lt;- seq(0,10,length.out=100)
s %&lt;&gt;%
  cos %&gt;% plot</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-7-1.png width=384 style=display:block;margin:auto></p><pre class=r><code>print(s)</code></pre><pre><code>## NULL</code></pre><p>We see that <span class="math inline">\(s\)</span> is <code>NULL</code>. Instead we may store the output in the middle of a sequence of pipes by using the <code>tee</code> operator <code>%T>%</code> as seen below. We begin the pipe with the assignment operator <code>&lt;-</code>. Note that <span class="math inline">\(s\)</span> now stores the output of the <span class="math inline">\(cos()\)</span> function.</p><pre class=r><code>par(mfrow=c(1,2))
s &lt;- seq(0,10,length.out=100)
s &lt;- s %&gt;%
  cos %T&gt;% plot
plot(s)</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-8-1.png width=1344 style=display:block;margin:auto></p><pre class=r><code>print(s[1:5])</code></pre><pre><code>## [1] 1.0000000 0.9949028 0.9796632 0.9544366 0.9194801</code></pre></div><div id=the-exposition-pipe class="section level3"><h3>The <code>exposition</code> pipe <code>%$%</code></h3><p>When using pipes, we may encounter a scenario in which we want the names on the left hand side of the pipe to be easily available to the right hand side. This is what the exposition pipe does. This is particularly useful when working with named data and lists. Below we work with the UKload dataset for an example.</p><pre class=r><code>head(UKload)</code></pre><pre><code>##     NetDemand       wM   wM_s95       Posan      Dow      Trend NetDemand.48
## 25      38353 6.046364 5.558800 0.001369941   samedi 1293879600        38353
## 73      41192 2.803969 3.230582 0.004109824 dimanche 1293966000        38353
## 121     43442 2.097259 1.858198 0.006849706    lundi 1294052400        41192
## 169     50736 3.444187 2.310408 0.009589588    mardi 1294138800        43442
## 217     50438 5.958674 4.724961 0.012329471 mercredi 1294225200        50736
## 265     50064 4.124248 4.589470 0.015069353    jeudi 1294311600        50438
##     Holy Year                Date
## 25     1 2011 2011-01-01 12:00:00
## 73     0 2011 2011-01-02 12:00:00
## 121    0 2011 2011-01-03 12:00:00
## 169    0 2011 2011-01-04 12:00:00
## 217    0 2011 2011-01-05 12:00:00
## 265    0 2011 2011-01-06 12:00:00</code></pre><pre class=r><code>UKload %&gt;%
  subset(Year == 2011) %$%
  cor(wM, NetDemand)</code></pre><pre><code>## [1] -0.6858647</code></pre><p>Without the exposition pipe this would be done in the following way.</p><pre class=r><code>UKload %&gt;%
  subset(Year == 2011) %&gt;%
  {cor(.$wM, .$NetDemand)}</code></pre><pre><code>## [1] -0.6858647</code></pre></div></div><div id=visualizations-with-ggplot2 class="section level2"><h2>Visualizations with ggplot2</h2><p>We will use ggplot2 for an exploratory analysis of the ASHRAE - Great Energy Predictor III dataset found <a href=https://www.kaggle.com/c/ashrae-energy-prediction>here</a> on Kaggle.</p><div id=data-setup class="section level3"><h3>Data setup</h3><pre class=r><code># set the seed for reproducibility
set.seed(1)

# load the whole dataset
data_train &lt;- read.csv(&quot;~/Downloads/energy_data/train.csv&quot;)

# inspect
head(data_train); dim(data_train)

# we load the other files and join them into one data frame
building_data &lt;- read.csv(&quot;~/Downloads/energy_data/building_metadata.csv&quot;)
weather_train &lt;- read.csv(&quot;~/Downloads/energy_data/weather_train.csv&quot;)

# join the data together
all_train &lt;- data_train %&gt;%
  left_join(building_data, by = &quot;building_id&quot;) %&gt;%
  left_join(weather_train, by = c(&quot;site_id&quot;, &quot;timestamp&quot;))

# check memory size
all_train %&gt;% object.size %&gt;% format(units = &quot;MB&quot;)

# we see that although building_metadata.csv, and weather_train.csv are very small files
# the combined data frame has size approx 1850Mb
# so we only keep a subset to work with
# keep only a subset of the dataset
nlevels(as.factor(all_train$building_id))
data_subset &lt;- all_train %&gt;% 
  filter(building_id %in% sample(1449, 150))
head(data_subset)

# let&#39;s save this data so we don&#39;t have to import the full dataset again
write.csv(data_subset, &quot;~/Downloads/energy_data/subset_combined_train.csv&quot;)</code></pre><p>The above code combined the multiple files, and saves a subset of the combined training data. The full dataset (1449 <code>building_id</code>s) has approximate size 1850Mb whereas the subset of 150 <code>building_id</code>s only uses 1.4b of memory. To avoid the unnecessary memory usage in the above step, the code has been ran once and the subset had been written to a .csv file.</p></div><div id=intro-to-ggplot2 class="section level3"><h3>Intro to <code>ggplot2</code></h3><p>Let’s import the dataset <code>data_subset</code> and add some useful variables such as the day, hour, etc.</p><pre class=r><code># import the dataset
data_subset &lt;- read.csv(&quot;~/Downloads/energy_data/subset_combined_train.csv&quot;)

# create new feature variables based on the date/time
data_subset &lt;- data_subset %&gt;%
  mutate(timestamp_ymd_hms = ymd_hms(timestamp),
         timestamp_hour = factor(hour(timestamp_ymd_hms)),
         timestamp_day = factor(day(timestamp_ymd_hms)),
         timestamp_week = factor(week(timestamp_ymd_hms)),
         timestamp_month = factor(month(timestamp_ymd_hms, label=TRUE)),
         timestamp_year = factor(year(timestamp_ymd_hms)),
         meter = factor(meter)
         )

# for basic plots
small_data_subset &lt;- data_subset %&gt;%
  subset(timestamp_month %in% c(&quot;Jun&quot;, &quot;Nov&quot;)) %&gt;%
  group_by(timestamp_hour, timestamp_month) %&gt;%
  summarise(avg_meter_reading = median(meter_reading))</code></pre><pre><code>## `summarise()` has grouped output by &#39;timestamp_hour&#39;. You can override using
## the `.groups` argument.</code></pre><p>In the above example we see that functions provided by the tidyverse make code much neater and easier to write. Feature engineering becomes simpler with functions such as <code>group_by()</code>. We now start from the basics and build plots with <code>ggplot2</code>.</p><p>Base R plots are called for their side effects rather than the returned value. When calling <code>plot</code> we indeed produce a plot, but the function doesn’t return anything of value. This is quite different to <code>ggplot2</code> in which we create and store a <code>ggplot</code> object, which we then call to produce a plot.</p><p>When using <code>ggplot</code> we add multiple layers to the plot. We initially create the plot object, which creates a blank canvas. We may then add a scatterplot or histogram layer. If we then wanted to add a title or legend, we would add these to our <code>ggplot</code> object.</p><p>Calling <code>ggplot</code> defines a blank canvas. We can then add a scatter plot to the canvas.</p><pre class=r><code># first plot
plot1 &lt;- ggplot(data = small_data_subset) + theme_bw()
# second plot
plot2 &lt;- plot1 + 
  geom_point(aes(x = timestamp_hour, y = avg_meter_reading, col=timestamp_month))
# plot both
grid.arrange(plot1, plot2, ncol=2) # using gridExtra package</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-13-1.png width=1344 style=display:block;margin:auto></p><p>When evaluating an object, R calls the generic <code>print</code> function. As our object has class <code>ggplot</code>, R calls the <code>print.ggplot</code> function. The main difference between <code>ggplot2</code> and <code>graphics</code> plotting methods is that <code>gplot2</code> separates the plot-building phase (defining a <code>ggplot</code> object and then adding layers) from the rendering phase (calling the <code>print</code> function).</p><p>A general template for creating a <code>ggplot</code> may look like:</p><pre class=r><code>ggplot(data = &lt;data.frame&gt;) +
  &lt;geom_layer&gt;(mapping = aes(&lt;variables_map&gt;))</code></pre><p>In this template</p><ul><li><code>ggplot</code> creates a <code>ggplot</code> object, with a <code>data.frame</code> as its main argument.</li><li><code>+</code> is an overloaded operator. On the left hand side we have a <code>ggplot</code> object, and on the right hand side is a layer or function that modifies the plot.</li><li><code>&lt;geom_layer></code> is a graphical layer, such as <code>geom_point</code>. Each layer needs a mapping.</li></ul><p>We may be interested in the energy usage of new and modern buildings vs older buildings. To gain some insight we use <code>dplyr</code>‘s <code>mutate</code> to create a new factor variable denoting whether the building is ’Old’ or ‘Modern’. To do this we use two approaches: one in which buildings older than the median building age are considered old and those newer are considered to be modern. Another approach is to define buildings built after the year 2000 to be modern and before 2000 to be old.</p><pre class=r><code>data_subset %&lt;&gt;%
  mutate(building_age_med = factor(as.logical(year_built &gt; median(year_built, na.rm=TRUE)),
                                   labels = c(&quot;Modern&quot;, &quot;Old&quot;)))

data_subset %&lt;&gt;%
  mutate(building_age_2 = factor((year_built &gt; 2000), 
                                 labels = c(&quot;Modern&quot;, &quot;Old&quot;)))

data_subset %&gt;%
  select(year_built, building_age_med, building_age_2) %&gt;%
  head()</code></pre><pre><code>##   year_built building_age_med building_age_2
## 1       2004              Old            Old
## 2       1996              Old         Modern
## 3       2002              Old            Old
## 4       1969              Old         Modern
## 5       2001              Old            Old
## 6       1986              Old         Modern</code></pre><p>We then use <code>dplyr</code> and <code>ggplot2</code> to plot a graph.</p><pre class=r><code># create data for building_age_med
data_subset_1 &lt;- data_subset %&gt;%
  filter(!is.na(building_age_med)) %&gt;%
  group_by(building_age_med, timestamp_hour) %&gt;%
  summarise(median_reading = median(meter_reading, na.rm=TRUE)) %&gt;%
  mutate(building_age_type = &quot;Median&quot;) %&gt;%
  dplyr::rename(building_age = building_age_med)</code></pre><pre><code>## `summarise()` has grouped output by &#39;building_age_med&#39;. You can override using
## the `.groups` argument.</code></pre><pre class=r><code># create subset of data for building_age_2 i.e. &gt;2000 or &lt;2000
data_subset_2 &lt;- data_subset %&gt;%
  filter(!is.na(building_age_2)) %&gt;%
  group_by(building_age_2, timestamp_hour) %&gt;%
  summarise(median_reading = median(meter_reading, na.rm=TRUE)) %&gt;%
  mutate(building_age_type = &quot;&gt;2000&quot;) %&gt;%
  dplyr::rename(building_age = building_age_2)</code></pre><pre><code>## `summarise()` has grouped output by &#39;building_age_2&#39;. You can override using
## the `.groups` argument.</code></pre><pre class=r><code>data_subset_comb &lt;- bind_rows(data_subset_1, data_subset_2, id=NULL)
data_subset_comb$building_age_type &lt;- factor(data_subset_comb$building_age_type,
                                             labels=c(&quot;&gt;2000&quot;, &quot;Median&quot;))

data_subset_comb %&gt;%
  filter(!is.na(building_age)) %&gt;%
  ggplot(aes(x=as.numeric(timestamp_hour), y=median_reading, col=building_age)) +
  facet_wrap(vars(building_age_type)) +
  geom_line()</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-16-1.png width=576 style=display:block;margin:auto></p><p>We clearly see on both facets that modern houses use less energy than old buildings In the left we see that energy usage increases dramatically around 1000 and decreases around 1400. This may imply that older buildings are less insulated than modern buildings, hence the need for heating the building throughout the day. We split the building age into decades below to further inspect the data.</p><pre class=r><code>data_subset &lt;- data_subset %&gt;%
  mutate(decade_built = as.factor(floor((year_built)/10)*10))

data_subset %&gt;%
  filter(timestamp_month == &quot;Jan&quot;) %&gt;%
  select(decade_built, timestamp_hour, meter_reading) %&gt;%
  filter(!is.na(decade_built), decade_built %in% seq(1950,2010,10)) %&gt;%
  group_by(decade_built, timestamp_hour) %&gt;%
  summarise(median_reading = median(meter_reading, na.rm=TRUE)) %&gt;%
  ggplot(aes(x=as.numeric(timestamp_hour), y=median_reading, col=decade_built)) +
  geom_line()</code></pre><pre><code>## `summarise()` has grouped output by &#39;decade_built&#39;. You can override using the
## `.groups` argument.</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-17-1.png width=384 style=display:block;margin:auto></p><p>This isn’t exactly what we expected, but it’s likely that there are higher-dimensional relationships within the data which we simply cannot capture with a 2D graph. There are many more factors which impact the average meter reading.</p><p>We may be interested in the median readings of different types of meter.</p><pre class=r><code>data_subset$meter &lt;- factor(data_subset$meter, levels = 0:3)

data_subset %&gt;%
  group_by(meter) %&gt;%
  ggplot(aes(x = log(meter_reading + 1), fill = meter)) +
  geom_density(alpha=0.4, adjust=1.5) +
  scale_fill_discrete()</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-18-1.png width=384 style=display:block;margin:auto></p><p>Let’s plot the median meter reading for each hour of the day.</p><pre class=r><code>data_subset %&gt;%
  group_by(timestamp_hour) %&gt;%
  summarise(median_meter_reading = median(meter_reading)) %&gt;%
  ggplot(aes(x=timestamp_hour, y=median_meter_reading)) +
  geom_point() +
  geom_smooth()</code></pre><pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-19-1.png width=384 style=display:block;margin:auto></p><p>We may be interested in a plot of median meter readings for each type of building in <code>primary_use</code>.</p><pre class=r><code>data_subset %&gt;%
  group_by(timestamp_hour, primary_use) %&gt;%
  summarise(median_meter_reading = median(meter_reading)) %&gt;%
  ggplot(aes(x = as.numeric(timestamp_hour), y = median_meter_reading)) +
  geom_line(colour = &quot;skyblue&quot;) +
  facet_wrap(vars(primary_use), scales=&quot;free&quot;) +
  theme_minimal() + 
  labs(title = &quot;Median meter reading over the day&quot;,
       subtitle = &quot;For different building uses&quot;,
       x = &quot;Hour of the day&quot;, y = &quot;Average median reading&quot;)</code></pre><pre><code>## `summarise()` has grouped output by &#39;timestamp_hour&#39;. You can override using
## the `.groups` argument.</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-20-1.png width=960 style=display:block;margin:auto></p><p>ggplot offers some nice tools for visualizing correlation matrices.</p><pre class=r><code># get the correlation matrix
corrmat &lt;- data_subset %&gt;%
  select(-site_id) %&gt;%
  select_if(is.numeric) %&gt;%
  drop_na() %&gt;%
  {round(cor(.),2)}

# melt into long format ready for ggplot2
corrlong &lt;- melt(corrmat)</code></pre><pre><code>## Warning in type.convert.default(X[[i]], ...): &#39;as.is&#39; should be specified by the
## caller; using TRUE

## Warning in type.convert.default(X[[i]], ...): &#39;as.is&#39; should be specified by the
## caller; using TRUE</code></pre><pre class=r><code># plot with ggplot2
plot1 &lt;- corrlong %&gt;%
  ggplot(aes(x=X1, y=X2, fill = value)) +
  geom_tile() +
  labs(title = &quot;Matrix of variable correlations&quot;, x = &quot;&quot;, y = &quot;&quot;) +
  theme(axis.text.x = element_text(angle=90, hjust=1))

# plot only correlations with meter_reading
corrlong$X1 &lt;-  factor(corrlong$X1)
plot2 &lt;- corrlong %&gt;%
  filter(X2 == &quot;meter_reading&quot;) %&gt;%
  select(X1, value) %&gt;%
  as.data.frame() %&gt;%
  ggplot(aes(x = reorder(X1, value), y = value)) +
  geom_col() +
  coord_flip() + 
  labs(title = &quot;Correlation of factors with meter reading&quot;, 
       x=&quot;&quot;, y=&quot;Correlation&quot;)

grid.arrange(plot1, plot2, ncol=2)</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-21-1.png width=1344 style=display:block;margin:auto></p><p>We are mostly interested in the factors which affect the meter reading. The above correlation matrix tells us that <code>meter_reading</code> is positively correlated with <code>square_feet</code> and <code>floor_count</code>. Let’s produce some plots to see the relationship.</p><pre class=r><code>data_subset %&gt;%
  filter(square_feet &lt;= 4e+05, 
         timestamp_month == c(&quot;Jun&quot;)) %&gt;%
  group_by(building_id, meter) %&gt;%
  summarise(avg_meter_reading = median(meter_reading), 
            square_feet = mean(square_feet)) %&gt;%
  ggplot(aes(x=square_feet, y=avg_meter_reading)) +
  geom_point() +
  geom_smooth(method=&quot;glm&quot;) +
  labs(title = &quot;Average meter readings in June&quot;, 
       subtitle = &quot;GLM overlaid in blue&quot;, 
       y = &quot;Average meter reading&quot;, x = &quot;Square feet&quot;)</code></pre><pre><code>## `summarise()` has grouped output by &#39;building_id&#39;. You can override using the
## `.groups` argument.
## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-22-1.png width=384 style=display:block;margin:auto></p><pre class=r><code>data_subset %&gt;%
  filter(building_id != 685, building_id != 803, # remove outliers
         timestamp_month %in% c(&quot;Jun&quot;), !is.na(floor_count)) %&gt;%
  group_by(floor_count) %&gt;%
  summarise(avg_meter_reading = median(meter_reading)) %&gt;%
  ggplot(aes(x=floor_count, y=avg_meter_reading)) +
  geom_col() +
  labs(title = &quot;Average meter readings in June&quot;, 
       y = &quot;Average meter reading&quot;, x = &quot;Number of floors&quot;)</code></pre><p><img src=https://jakespiteri.co.uk/portfolio/computing-1/report-6/index_files/figure-html/unnamed-chunk-23-1.png width=384 style=display:block;margin:auto></p><p>The graph seems to make sense. As the number of floors increases, the amount of energy needed to heat the building increases. There were some outliers which have to be removed such as the building with id <span class="math inline">\(685\)</span> which has 5 floors and approximately <span class="math inline">\(250,000\)</span> square feet! It uses much more energy than we would expect.</p></div></div></div></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://jakespiteri.co.uk/portfolio/computing-1/report-5/><span class=title>« Prev</span><br><span>Portfolio Report 5: Functional and object-oriented programming</span></a>
<a class=next href=https://jakespiteri.co.uk/portfolio/computing-1/report-7/><span class=title>Next »</span><br><span>Portfolio Report 7: Debugging and Performance</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://jakespiteri.co.uk/>Jake Spiteri</a></span>
<span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>