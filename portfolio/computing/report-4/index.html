<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="Jake Spiteri">
<meta name="description" content="Vectorization Vectorization is the process of replacing the use of loops in code, with a single operation applied elementwise to the vector. In vectorizing code, the multiple instructions running the same operation in a for loop are replaced by a single instruction which applies the operation to multiple elements in a vector.
Vectorization is much faster than using for loops in interpreted languages such as R, Matlab, and Python. To see this in practice, we will look at some examples." />
<meta name="keywords" content="statistics, mathematics, data science, machine learning, deep learning" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="#252627" />
<link rel="canonical" href="https://jakespiteri.co.uk/portfolio/computing/report-4/" />


    <title>
        
            Portfolio Report 4: Vectorization and parallel computing :: Jake Spiteri  — Jake Spiteri
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">



<link rel="stylesheet" href="https://jakespiteri.co.uk/main.min.7bfbbe12786fa0ded4b4c0d792cbb36a5bd0bdb0b856dde57aa7b1f6fe0f2b87.css">


    
        <link rel="stylesheet" type="text/css" href="static/style.css">
    



    <link rel="apple-touch-icon" sizes="180x180" href="https://jakespiteri.co.uk/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://jakespiteri.co.uk/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://jakespiteri.co.uk/favicon-16x16.png">
    <link rel="manifest" href="https://jakespiteri.co.uk/site.webmanifest">
    <link rel="mask-icon" href="https://jakespiteri.co.uk/safari-pinned-tab.svg" color="#252627">
    <link rel="shortcut icon" href="https://jakespiteri.co.uk/favicon.ico">
    <meta name="msapplication-TileColor" content="#252627">
    <meta name="theme-color" content="#252627">

<meta itemprop="name" content="Portfolio Report 4: Vectorization and parallel computing">
<meta itemprop="description" content="Vectorization Vectorization is the process of replacing the use of loops in code, with a single operation applied elementwise to the vector. In vectorizing code, the multiple instructions running the same operation in a for loop are replaced by a single instruction which applies the operation to multiple elements in a vector.
Vectorization is much faster than using for loops in interpreted languages such as R, Matlab, and Python. To see this in practice, we will look at some examples.">

<meta itemprop="wordCount" content="1781">
<meta itemprop="image" content="https://jakespiteri.co.uk"/>



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://jakespiteri.co.uk"/>

<meta name="twitter:title" content="Portfolio Report 4: Vectorization and parallel computing"/>
<meta name="twitter:description" content="Vectorization Vectorization is the process of replacing the use of loops in code, with a single operation applied elementwise to the vector. In vectorizing code, the multiple instructions running the same operation in a for loop are replaced by a single instruction which applies the operation to multiple elements in a vector.
Vectorization is much faster than using for loops in interpreted languages such as R, Matlab, and Python. To see this in practice, we will look at some examples."/>












<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-159259654-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>





<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css' rel='stylesheet' type='text/css' />



    </head>

    <body class="">
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="https://jakespiteri.co.uk/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text">$ cd /home/</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://jakespiteri.co.uk/about/">About</a></li><li><a href="https://jakespiteri.co.uk/portfolio/">Portfolio</a></li><li><a href="https://jakespiteri.co.uk/posts/">Posts</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            

            <span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>
</span>
        </span>
    </span>
</header>


            <div class="content">
                
    <main class="post">

        <div class="post-info">
            
            </p>
        </div>

        <article>
            <h2 class="post-title"><a href="https://jakespiteri.co.uk/portfolio/computing/report-4/">Portfolio Report 4: Vectorization and parallel computing</a></h2>

            

            <div class="post-content">
                


<div id="vectorization" class="section level1">
<h1>Vectorization</h1>
<p>Vectorization is the process of replacing the use of loops in code, with a single operation applied elementwise to the vector. In vectorizing code, the multiple instructions running the same operation in a for loop are replaced by a single instruction which applies the operation to multiple elements in a vector.</p>
<p>Vectorization is much faster than using for loops in interpreted languages such as R, Matlab, and Python. To see this in practice, we will look at some examples.</p>
<p>We consider summing the cosine of each component of a vector.</p>
<pre class="r"><code># set the seed for reproducibility
set.seed(123)

# uses a for loop
add_cos1 &lt;- function(x) {
  sum &lt;- 0
  for (i in 1:length(x)) {
    sum &lt;- sum + cos(x[i])
  }
  return(sum)
}

# uses vectorization
add_cos2 &lt;- function(x) sum(cos(x))

x = 1:1e7
t1 &lt;- system.time(add_cos1(x))
t2 &lt;- system.time(add_cos2(x))</code></pre>
<pre class="r"><code>t1 </code></pre>
<pre><code>##    user  system elapsed 
##   0.825   0.001   0.827</code></pre>
<pre class="r"><code>t2</code></pre>
<pre><code>##    user  system elapsed 
##   0.291   0.052   0.343</code></pre>
<p>At the time of running, this provided a speedup of 2.4 times. We also note that the vectorized code is also easier to read.</p>
<div id="high-dimensional-vectorization" class="section level2">
<h2>High-dimensional vectorization</h2>
<p>The example above shows that for loops are quite inefficient. It is now easy to see that nested for loops are very inefficient, and should be avoided.</p>
<p>There are many reasons we may want to use nested for loops. We may want to run a simulation <span class="math inline">\(n_{sim}\)</span> times, where each simulation consists of <span class="math inline">\(n\)</span> operations.</p>
<p>As an example, we consider the average value produced by tossing a fair six-sided die <span class="math inline">\(n=500\)</span> times. We expect our data to center around <span class="math inline">\(\frac{1+2+3+4+5+6}{6}=3.5\)</span>. We simulate the experiment <span class="math inline">\(n_{sim} = 1000\)</span> times.</p>
<pre class="r"><code>toss_die1 &lt;- function(nsim, n) {
  average &lt;- numeric(nsim)
  for (i in 1:nsim) {
    counts &lt;- numeric(n)
    for (j in 1:n) {
      counts[j] &lt;- sample(1:6, 1)
    }
    average[i] &lt;- mean(counts)
  }
  return(average)
}

toss_die2 &lt;- function(nsim, n) {
  tosses &lt;- matrix(sample(1:6, n*nsim, replace=TRUE), nrow=nsim, ncol=n)
  return(rowSums(tosses)/n)
}</code></pre>
<p>We now test the runtime of the nested for loop version, and the vectorized version.</p>
<pre class="r"><code>nsim &lt;- 1000; n &lt;- 500
t1 &lt;- system.time(toss_die1(nsim, n)); t1</code></pre>
<pre><code>##    user  system elapsed 
##   2.215   0.002   2.218</code></pre>
<pre class="r"><code>t2 &lt;- system.time(toss_die2(nsim, n)); t2</code></pre>
<pre><code>##    user  system elapsed 
##   0.042   0.000   0.042</code></pre>
<p>We see that nested for loops are <em>very</em> slow and should be avoided when possible. In this case the vectorized code provides a speedup of 53 times! We will use the vectorized function in the following.</p>
<pre class="r"><code>nsim &lt;- 10000; n &lt;- 500
average_value &lt;- toss_die2(nsim,n)
hist(average_value, breaks = 30)</code></pre>
<p><img src="https://jakespiteri.co.uk/portfolio/computing/Report-4_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Let’s look at a demonstration of Law of Large Numbers. We plot the cumulative mean as the number of throws increases.</p>
<pre class="r"><code>nsim &lt;- 3000; n &lt;- 1
plot(1:nsim, cumsum(toss_die2(nsim, n))/1:nsim, type = &#39;l&#39;,
     main=&#39;Average dice roll&#39;,
     xlab = &#39;Number of rolls&#39;, ylab=&#39;Cumulative mean&#39;)
abline(h=3.5, col=&#39;red&#39;, lty = 2)</code></pre>
<p><img src="https://jakespiteri.co.uk/portfolio/computing/Report-4_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
</div>
<div id="the-apply-family" class="section level1">
<h1>The <code>apply</code> family</h1>
<p>The <code>apply</code> family consists of <code>apply()</code>, <code>lapply()</code>, <code>sapply()</code>, and <code>mapply()</code>. These functions apply a specified function to elements in a data structure. These functions can be viewed as alternatives to for loops; they are often slower but may simplify and enhance the readability of code.</p>
<ol style="list-style-type: decimal">
<li><p><code>apply(X, MARGIN, FUN, ...)</code> — This function applies a function to a vector or matrix. The MARGIN argument determines whether the function is applied over rows or columns, or both.</p></li>
<li><p><code>lapply(X, FUN, ...)</code> — This function is similar to <code>apply</code> but it applies a function over a vector or list and returns a list.</p></li>
<li><p><code>sapply(X, FUN, ...)</code> — This is a wrapper function of <code>lapply</code> which simplifies the output by returning a vector, matrix, or an array when specified using <code>simplify = &quot;array&quot;</code>.</p></li>
<li><p><code>mapply(FUN, ...)</code> — This is a multivariate version of <code>sapply</code>. <code>mapply</code> applies the function FUN to the first elements of each subsequent <code>...</code> argument.</p></li>
</ol>
<div id="examples" class="section level2">
<h2>Examples</h2>
<p>Below are some examples using the <code>apply</code> family of functions.</p>
<pre class="r"><code>## apply
mat &lt;- matrix(rep(1, 12), 3, 4) # 3x4 matrix of 1s

# apply sum to each row --- i.e. sum over columns
apply(mat, 1, sum)</code></pre>
<pre><code>## [1] 4 4 4</code></pre>
<pre class="r"><code># apply sum to each column --- i.e. sum over rows
apply(mat, 2, sum) </code></pre>
<pre><code>## [1] 3 3 3 3</code></pre>
<pre class="r"><code># apply sum to each element --- this does not do anything if FUN = sum
apply(mat, c(1,2), sum)</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4]
## [1,]    1    1    1    1
## [2,]    1    1    1    1
## [3,]    1    1    1    1</code></pre>
<pre class="r"><code># apply our own function to each element
apply(mat, c(1,2), function(x) 2*x)</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4]
## [1,]    2    2    2    2
## [2,]    2    2    2    2
## [3,]    2    2    2    2</code></pre>
<pre class="r"><code>## lapply
vec &lt;- rep(1,3)
lis &lt;- list(seq = 1:4, rep = rep(1,4))

# get cosine of each element in a vector
lapply(vec, cos)</code></pre>
<pre><code>## [[1]]
## [1] 0.5403023
## 
## [[2]]
## [1] 0.5403023
## 
## [[3]]
## [1] 0.5403023</code></pre>
<pre class="r"><code># apply cosine to list
lapply(lis, cos)</code></pre>
<pre><code>## $seq
## [1]  0.5403023 -0.4161468 -0.9899925 -0.6536436
## 
## $rep
## [1] 0.5403023 0.5403023 0.5403023 0.5403023</code></pre>
<pre class="r"><code>## sapply
# get cosine of each element in a vector
sapply(vec, cos)</code></pre>
<pre><code>## [1] 0.5403023 0.5403023 0.5403023</code></pre>
<pre class="r"><code># apply cosine to list
sapply(lis, cos)</code></pre>
<pre><code>##             seq       rep
## [1,]  0.5403023 0.5403023
## [2,] -0.4161468 0.5403023
## [3,] -0.9899925 0.5403023
## [4,] -0.6536436 0.5403023</code></pre>
<pre class="r"><code>## mapply
# sum two vectors elementwise
mapply(&#39;+&#39;, 1:3, 4:6)</code></pre>
<pre><code>## [1] 5 7 9</code></pre>
<pre class="r"><code># seq(1, 5), seq(2, 5), ...
mapply(seq, 1:5, 5)</code></pre>
<pre><code>## [[1]]
## [1] 1 2 3 4 5
## 
## [[2]]
## [1] 2 3 4 5
## 
## [[3]]
## [1] 3 4 5
## 
## [[4]]
## [1] 4 5
## 
## [[5]]
## [1] 5</code></pre>
</div>
</div>
<div id="map-reduce-and-filter" class="section level1">
<h1><code>Map</code>, <code>Reduce</code>, and <code>Filter</code></h1>
<p>These functions can use lambda expressions similar to the above <code>apply</code> family. These are short functions which are sometimes referred to as anonymous functions, as they are not assigned to a variable. Lambda expressions allow us to produce quite complicated functionality in one line.</p>
<p>Below is a quick summary of the functions introduced in this section:</p>
<ol style="list-style-type: decimal">
<li><p><code>Map</code> — This function maps a function to every element in a vector.</p></li>
<li><p><code>Reduce</code> — This function performs a function on pairs of elements in a vector, iteratively, and returns a single number.</p></li>
<li><p><code>Filter</code> — Tests every element in a vector and only returns those that satisfy the condition.</p></li>
</ol>
<div id="examples-1" class="section level2">
<h2>Examples</h2>
<p>Below are some examples demonstrating the above functions.</p>
<pre class="r"><code>vec &lt;- 1:3

# Map cosine to every element in a vector
Map(cos, vec)</code></pre>
<pre><code>## [[1]]
## [1] 0.5403023
## 
## [[2]]
## [1] -0.4161468
## 
## [[3]]
## [1] -0.9899925</code></pre>
<pre class="r"><code># Reduce
Reduce(function(x, y) x + 2*y, vec)</code></pre>
<pre><code>## [1] 11</code></pre>
<pre class="r"><code># Filter
Filter(function(x) x %% 3 == 0, vec) </code></pre>
<pre><code>## [1] 3</code></pre>
</div>
</div>
<div id="parallel-computing" class="section level1">
<h1>Parallel computing</h1>
<p>Parallelization is the process of using multiple CPU cores at the same time, to solve different parts of a problem. Often when working on large computational problems, we will encounter a bottleneck. We may encounter a</p>
<ul>
<li>CPU-bound: Our computations take too much CPU time.</li>
<li>Memory-bound: Our computations use too much memory.</li>
<li>I/O bound: It takes too long to read/write from disk.</li>
</ul>
<p>Parallel computing helps us overcome CPU bounds by working with more than one core at a time. This means that if our computer has four physical cores, then we can distribute our computation across four cores. In theory, this would speed up our computation by four times but it is not the case in practice due to the other bounds described above. Part of being a good R programmer is being able to write fast and efficient code.</p>
<div id="parallelize-using-mclapply" class="section level2">
<h2>Parallelize using <code>mclapply</code></h2>
<p><code>mclapply</code> is a multi-core version of <code>lapply</code>.</p>
<pre class="r"><code>library(parallel)
library(doParallel)</code></pre>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Loading required package: iterators</code></pre>
<pre class="r"><code># detect cores
detectCores()</code></pre>
<pre><code>## [1] 8</code></pre>
<pre class="r"><code># demonstrate that distributing over 4 cores does not provide speed up of 4 times
system.time(lapply(1:8, function(x) Sys.sleep(0.5)))                # 4 seconds</code></pre>
<pre><code>##    user  system elapsed 
##   0.004   0.000   4.008</code></pre>
<pre class="r"><code>system.time(mclapply(1:8, function(x) Sys.sleep(0.5), mc.cores=4))  # expect 1 second</code></pre>
<pre><code>##    user  system elapsed 
##   0.003   0.012   1.016</code></pre>
</div>
<div id="parallelize-using-foreach" class="section level2">
<h2>Parallelize using <code>foreach</code></h2>
<p><code>foreach</code> seems a little like a <code>for</code> loop. However <code>foreach</code> uses binary operators <code>%do%</code> and <code>%dopar%</code>, and also returns a list as output. It’s useful to use <code>foreach</code> with <code>%do%</code> to evaluate an expression sequentially and store all outputs in a data struture — by default this is a list but the behavior can be changed using the argument <code>.combine</code>.</p>
<pre class="r"><code>library(foreach)

# run sequentially using %do%
foreach(i=1:3) %do% {i*i}</code></pre>
<pre><code>## [[1]]
## [1] 1
## 
## [[2]]
## [1] 4
## 
## [[3]]
## [1] 9</code></pre>
<pre class="r"><code># change output to vector
foreach(i=1:3, .combine=&quot;c&quot;) %do% {i*i}</code></pre>
<pre><code>## [1] 1 4 9</code></pre>
<p>The above functions use the operator <code>%do%</code> and therefore run sequentially. If we simply replace the operator with <code>%dopar%</code> R will run the computations in parallel. The above computations are so simple that it’s probably not worth implementing them in parallel. Let’s look at a little example using Markov chain Monte Carlo, in which we may want to run multiple chains to test for pseudo-convergence. All of the parallelization is in the <code>simulate.chains</code> function. Note that in order to run the computations in parallel we must register the parallel backend using <code>registerDoParallel(&lt;cores&gt;)</code> before <code>foreach</code>. When we are finished we should run <code>stopImplicitCluster()</code>.</p>
<pre class="r"><code># returns the transition kernel P(x)
make.metropolis.hastings.kernel &lt;- function(pi, Q) {
  q &lt;- Q$density
  P &lt;- function(x) {
      z &lt;- Q$sample(x)
      alpha &lt;- min(1, pi(z) * q(z, x) / pi(x) / q(x, z))
      if(runif(1) &lt; alpha) {
        return(z)
      } else {
        return(x)
      }
  }
  return(P)
}

make.normal.proposal &lt;- function(sigma) {
  Q &lt;- list()
  Q$sample &lt;- function(x) {
    return(rnorm(length(x), x, sigma))
  }
  Q$density &lt;- function(x, z) {
    return(dnorm(z, x, sigma))
  }
  return(Q)
}

simulate.chains &lt;- function(P, x0, n, n.chains, n.cores = 4) {
  # parallelize chains
  registerDoParallel(n.cores)
  simulations &lt;- foreach(i=1:n.chains, .combine=&quot;rbind&quot;) %dopar% {
    x &lt;- x0[i]
    foreach(i=1:n, .combine=&quot;c&quot;) %do% {P(x)}
  }
  stopImplicitCluster()
  return(simulations)
}</code></pre>
<p>Below we sample from a mixture distribution: The weighted mixture of two normal distributions <span class="math inline">\({Z \sim 0.6X + 0.4Y}\)</span>, where <span class="math inline">\(X \sim N(-2,1)\)</span>, <span class="math inline">\(Y \sim N(5, 2^2)\)</span>. We use a <span class="math inline">\(N(0,1)\)</span> proposal distribution. We will run <span class="math inline">\(4\)</span> chains in parallel and test for pseudo-convergence by looking at the trace of the chains. Each chain is initialized using a <span class="math inline">\(U[-10,10]\)</span> distribution.</p>
<pre class="r"><code># generate markov chain using MH algorithm
# target: mixture of two normals
n &lt;- 5e3; set.seed(123)
target &lt;- function(x) {0.6*dnorm(x, -2, 1) + 0.4*dnorm(x, 5, 2)}
xs &lt;- simulate.chains(make.metropolis.hastings.kernel(target, make.normal.proposal(1)), 
                      runif(4,-10,10), n, 4)

# setup plot space
par(mfrow=c(2,2))

# plot the chains
ylimits &lt;- c(min(xs), max(xs))
for(i in 1:4){
  plot(1:n, xs[i,], type = &#39;l&#39;, xlab=&quot;iteration&quot;, ylim=ylimits,
       ylab=&quot;x&quot;, main=paste0(&quot;Trace of Markov chain &quot;, i))
}</code></pre>
<p><img src="https://jakespiteri.co.uk/portfolio/computing/Report-4_files/figure-html/unnamed-chunk-12-1.png" width="960" /></p>
<p>We see that the traces do not converge to the same distribution! This tells us that the chains are not fully exploring the state space and thus we must adjust our proposal distribution.</p>
</div>
</div>

            </div>
        </article>

        <hr />

        <div class="post-info">
  			</div>

        
    </main>

            </div>

            
                <footer class="footer">
    <div class="footer__inner">
        <div class="footer__content">
            <span>&copy; 2020</span>
            
                <span><a href="https://jakespiteri.co.uk">Jake Spiteri</a></span>
            
            <span><a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0</a></span>
            <span> <a href="https://jakespiteri.co.uk/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 20 20" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a></span>
        </div>
    </div>
    <div class="footer__inner">
    </div>
</footer>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>



<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>


    <script src="https://jakespiteri.co.uk/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  </body>
</html>
            
        </div>

        




<script type="text/javascript" src="https://jakespiteri.co.uk/bundle.min.2d5469329143160ae2456a69c3c76dc2d0a3b212b46afe291a51bd68650ed6f8697e001dab54f1c272c77ce08092a8c55e5bb4314e0ee334aab4b927ec896638.js" integrity="sha512-LVRpMpFDFgriRWppw8dtwtCjshK0av4pGlG9aGUO1vhpfgAdq1TxwnLHfOCAkqjFXlu0MU4O4zSqtLkn7IlmOA=="></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-159259654-1', 'auto');
        ga('send', 'pageview');
    </script>



    </body>
</html>
